# 大型网站技术架构核心原理与案例分析  
> --阿里“教授” 李智慧
principle of large sites

###  1. 大型网站架构演化
#### 1.2大型网站架构演化发展历程

 >> *本书1.2部分架构的图例很清晰重要*
 
    1. _初始阶段_，  一台服务器，应用程序，文件，数据库都在一起；一个基于所有开源软件的小网站建立；
     2. _用户增加_， 应用服务和数据服务分离  应用程序在一台服务器，需要处理复杂的业务逻辑，所以需要CPU又快又强大； 数据库在一台服务器，需要快速磁盘检索和数据缓存，因此需要更快的硬盘和更大的内存； 文件服务器在另一台服务器，需要存放上传的文件，需要更大的硬盘。
    3. _使用缓存改善网站性能_，  由于用户增多，数据库压力太大导致延迟访问，由此：数据访问遵循2/8法则，所以想到使用缓存。 缓存分2种，一种应用服务器本地缓存，这种受服务器内存限制，且会与应用服务器争内存；另一种是使用远程分布式集群缓存，部署大内存服务器作为缓存服务器，可以在理论上做到不受内存容量限制的缓存服务；
    4. _使用应用服务器集群改善网站的并发处理能力_，使用集群是网站解决高并发、海量数据问题的常用手段。 用户过于庞大，不要一味加大服务器内存，性能；应用服务器实现集群是网站可伸缩集群架构设计中较为简 单成熟的一种。
    此时通过负载均衡调度服务器，可将来自用户浏览器的访问请求分发到应用服务器集群中任何一台服务器上，压力增大的话在集群中加入更多服务器即可，使应用服务器的负载压力不再成为整个网站的瓶颈。
    5. _数据库读写分离_，  网站使用缓存后，绝大部分数据库操作访问都可以不通过数据库就能完成，但仍有一些写操作或缓存过期，缓存不命中的操作需要访问数据库。用户增大时，数据库又成为网站服务支持的瓶颈。
    大部分数据库提供主从热备功能，因此配置主从数据库关系，可以将一台数据库服务器数据更新到另一台服务器上，利用这个数据库特性实现读写分离。此时，通常在应用服务器端使用专门的数据访问模块，读写数据。
    6. _使用反向代理和cdn加速网站响应_
    国内复杂的网络环境，不同地区用户访问网站速度差别很大。加入网站响应主要有反向代理和CDN加速；2者都是经过负载均衡调度服务器请求的，CDN和反向代理基本原理都是缓存，cdn是从部署在网络提供商的机房服务器取缓存，反向代理从反向代理的服务器取真实应用服务器的缓存。
     使用CDN和反向代理目的都是尽早返回数据给用户，取缓存服务器的数据，一方面加快用户访问速度，另一方面减轻后端服务器的负载压力；
    7. _使用分布式文件系统和分布式数据库系统_。
     任何单一的服务器都满足不了大型网站持续增长的业务需求，数据库读写分离是拆分了2台服务器，随着数据增长，最终需要分布式数据库和分布式文件系统服务器。
    _分布式数据库是网站数据拆分的最后手段_，只有单表数据规模非常庞大才使用，不到不得已，网站更常用数据库拆分手段是业务分库，将不同业务的数据库部署在不同的物理服务器上。
    8. _使用noSql和搜索引擎_
    随着网站业务复杂化，对数据存储和检索需求也越来越复杂，网站需要采用一些非关系型数据库技术如NoSql和非数据库查询技术如搜索引擎。
    者2者都是源自互联网技术手段，对可伸缩的分布式特性具有更好的支持，应用服务器则通过一个统一的数据访问模块访问各种数据，减轻应用程序管理诸多数据源的麻烦。
    9. _业务拆分_    
    大型购物交易网站，会拆分各个业务模块，如商铺，订单，卖家，买家。分归不同的业务团队负责。
    10. _分布式服务_
     通过分布式服务调用共用业务服务（可复用业务连接数据库），来完成具体的业务操作。云计算平台已经作为一种基础资源出售，中小企业不用注重实现细节，直接租用服务即可。

###  2. 大型网站架构模式
_*大型网站架构思路：拆分，从横向纵向拆分，从逻辑上物理上拆分，拆分的粒度很细，在物理上实现微服务集群，远程协同调用工作，降低访问压力*_

>   我们通过学习掌握大型网站架构的一般思路和解决方案，以指导我们的架构设计 

>   为解决大型网站面临的高并发访问，海量数据处理，高可靠运行这些挑战，大型互联网公司提出许多解决方案以实现高性能，高可用，易伸缩可扩展安全等架构目标；

#### 2.1 网站架构模式
   1. 分层  *横向分思想* 各模块分层，例如视图层，业务层，持久层，各模块拆分，人员负责维护自己的模块，保证接口稳定即可；
       分层首先是用在规划软件清晰的逻辑结构便于开发，后来可以将不同层部署到不同服务器上，分层结构对网站支持高并发分布式方向发展至关重要，网站从小就应该分层。
    2. 分割  *纵向分思想*  网站越大，越需要纵向分割，比如在业务层分割，将粒度分割的很细，如购物，论坛，搜索，广告各模块，购物业务比较重还可以细分，如分割机票酒店业务，3C业务，小商品等等细的模块。
       这些模块不管是在逻辑上还是物理部署上，都是独立的。
    3. 分布式  分布式有自身的一些缺陷，如数据一致性，事物等的处理。
   * 常用分布式方案：分布式应用和服务（不同应用复用共同的服务，便于业务功能扩展）；
   * 分布式静态资源（动静分离）；
   * 分布式数据和存储（数据量p级别，一般分布存储，noSql产品一般也是分布式）； 
   * 分布式计算（业务的计算规模很庞大，如数据仓库数据分析统计，网站普遍使用Hadoop及其mapReduce分布式计算框架进行大数据量批处理计算（特点是移动计算而非移动数据，将计算程序分到数据所在位置以加速计算和分布式计算））
   * 此外，还有支持网站线上服务器配置实时更新的分布式配置，分布式环境下实现并发和协同的分布式锁；支持云存储的分布式文件系统等。
  4. 集群 
     集群是针对一部分用户集中访问的内容，做的相同应用的集群化部署，通过负载均衡设备对外提供服务。 集群提高系统的可用性，一方面提供备份，一方面解决并发压力。
  5. 缓存
     缓存就是将数据放在距离计算最近的位置以加快处理速度。
    * cdn 内容分发网络，部署在距离最近的运营商服务器，将一些常用的较少改变的数据缓存。 
    * 反向代理 反向代理，用户请求到达网络数据中心时，最先访问的是反向代理服务器，这里缓存了静态资源，不需要请求中心服务器就可返回数据给用户。
    * 本地缓存 应用服务器本地（内存）缓存热点数据，直接返回数据给请求。
    * 分布式缓存  大型网站缓存数据量大，缓存数据放到分布式集群。
  6. 异步
   * 系统解耦的一个重要手段是异步，单一服务器内部可通过多线程共享内存队列的方式实现异步，处在业务操作前面的线程将输出写入队列，后面的线程从队列读取数据进行处理。
   * 在分布式系统中，多个服务器通过分布式消息队列实现异步，分布式消息队列可看做是内存队列的分布式部署。
   * 异步队列是典型的生产者消费者模式。两者不存在直接调用，只要保持数据结构不变，彼此功能实现可以随意变化而不相互影响。
   * 异步消息队列有如下特性。
   1. 特高系统可用性，消费者宕机，生产者不影响工作；
   2. 加快网站响应速度 处在业务前端的生产者服务器处理完业务请求后，数据写入消息队列，不需要等消费者服务器处理即可返回，响应延迟减少
   3. 消除并发访问高峰 大流量访问时，使用消息队列，请求数据放入队列中，等待消费者服务器依次处理，不会对整个网站造成太大压力。
   4. 使用异步需注意场景，！
  7. 冗余 
     冗余及备份，对服务器备份形成集群，对数据定时备份，对数据库进行主从分离，实时同步热备份。 重要内容全球灾备数据中心。
  8. 自动化
     无人值守状况下网站可正常运行，目前大公司的自动化一般有 发布过程自动化，自动化代码管理，自动化测试，自动化安全监测，部署，自动化报警，失效回复等等。
     自动化贯穿整个网站开发以及运维过程。
  9. 安全
    * 例如 通过密码手机校验码进行身份验证，登录。 对登录，交易信息加密。网站使用验证码识别机器人防止滥用资源，对xss，sql注入等黑客攻击，进行编码转换等手段，对垃圾信息过滤，对交易等重要数据操作进行风险控制。

#### 2.2 架构模式在新浪微博的应用（_举例说微博具体怎么使用架构模式 完美_）
   _*新浪分三层部署*_

  1. 新浪微博从小网站lamp linux apache mysql php发展起来，现在系统分为三层，最下层是基础服务层，提供数据库，缓存，存储搜索等数据服务，以及其他一些
  基础的技术服务，这些服务支撑了新浪微博的海量数据和高并发访问，是整个系统的技术基础。
  2. 中间层是平台服务和应用服务层，新浪微博的核心是微博，关系和用户，他们被拆成独立的服务模块，通过依赖调用和共享基础数据构成了新浪微博的业务基础。
  3. 最上层是API和新浪微博业务层，由客户端和第三方应用通过调用api集成到新浪微博系统，共同组成一个生态系统。

  4. 这些被分层和分割后的业务模块和基础技术模块分布式部署，每个模块部署到一个独立的服务器集群上，通过远程调用方式相互依赖，新浪早期使用过MPSS技术，将
  多个应用部署到一台服务器，改变端口实现资源最大化利用，现在常用的方式是将物理机虚拟成多个虚拟机，再在虚拟机上部署应用，这样可以不改变端口部署应用。
  5. 新浪早期技术机构中，微博发布采用同步推模式，用户发布微博会立即将内容推送到关注人的推送列表中，这样明星用户发起微博会导致系统压力很大，延迟很慢；    后来改为异步推拉结合的方式，用户发表微博后系统将微博写入消息队列后立即返回，用户响应迅速，
  消息队列消费者任务将微博推送给当前在线的粉丝订阅列表中，非在线用户登陆后再根据关注列表拉去微博列表。
 
    由于微博刷新频繁，新浪微博使用多级缓存策略，热门微博和明星用户微博缓存在所有服务器上，在线用户的近期微博_缓存_在分布式缓存集群中，常见的刷微博操作，几乎全是缓存访问操作，可获得很好的系统性能。
    
    为提高系统整体可用性和性能，新浪微博启用了_多个数据中心_，这些数据中心既是地区用户访问中心，方便用户就近访问提高访问速度，也是数据冗余复制的灾备中心，所有用户和微博数通过远程消息系统在不同的数据中心之间_同步_，提升系统可用性。
    
    同时，新浪微博开发了一系列_自动化工具_，包括自动化监控，自动挂发布，自动化故障修复等。这些自动化工具可改善运维水平提高系统可用性。
 
    在_安全性_上，由于微博的开放性，遇到一系列安全挑战如垃圾内容，僵尸粉，微博攻击从未停止，除一般的安全策略，微博还在开放平台上使用多级安全审核策略以保护系统和用户。

#### 2.3 小结
    在程序设计与架构设计领域，模式变得越来越重要，正确使用模式可以预解决系统日后出现的一些问题，而模式的使用主要是明白使用场景，生搬硬套效果可能适得其反，适合自己应用场景，对模式“微创新”也是让人耳目一新的。

### 3.大型网站核心架构要素
    >>架构是最高层次的规划，例如人生蓝图，职业规划，是整体上的一个定性。
  
   一般来说，除了当前的系统功能需求外，软件架构还需考虑关注性能、可用性、伸缩性、扩展性和安全性这5个架构要素。架构设计过程中需要平衡这5个要素之间的关系以实现需求和架构目标，也可通过考察这些架构要素来衡量一个软件架构设计的优劣，判断其是否满足期望。
#### 3.1 性能 （主要是访问速度快）
    网站性能主要体现在网站响应速度上，响应差会严重影响用户体验，性能提升可以在浏览器访问服务器过程的各个环节下手处理。

    * 在浏览器端，可以通过浏览器缓存，使用页面压缩，合理布局页面，减少cookie传输等手段改善性能。
    * 可以使用_cdn_，将网站静态内容缓存到离用户近的网络服务商机房；可以在网站机房部署_反向代理服务器_，缓存热点文件，加快访问速度，减轻应用服务器负载压力。
    * 在应用服务器端，可使用服务器本地缓存和分布式缓存，通过_缓存_内的热点数据处理用户请求，加快请求处理过程，减轻数据库负载压力。
    * 通过异步操作将用户请求发送至_消息队列_等待后续任务处理，而当前请求直接返回响应给用户。
    * 在网站有很多用户高并发请求情况下，可将多台应用服务器组成集群共同对外服务，提升整体处理能力，改善性能。
    * 在_代码_层面，可通过使用多线程，改善内存管理等手段优化性能。
    * 在数据库_服务器端_，索引，缓存，sql优化等性能优化手段已经比较成熟。而方兴未艾nosql数据库在性能方面的优势也日趋明显。
    
    衡量网站性能有一系列指标，重要的有响应时间，tps,系统性能计数器等，通过测试这些指标以确定系统设计是否达到目标。这些指标也是网站监控的重要参数，监控这些指标可分析系统瓶颈，
预测网站容量，并对异常指标进行报警，保障系统可用性。网站需要长时间运行还必须保证在持续运行且访问压力不均匀的情况下保持稳定的性能特性。

#### 3.2 可用性 （保持高可用，不会被宕机影响）
    一些知名大型网站可用性可以做到4个9以上的可用性，也就是可用性超过_99.99%_；
    商用服务器硬件并不保证不_宕机_，所以高可用的前提是假设服务器每天都有一部分宕机，再此情况下保持高可用。

    网站高可用的主要手段是_冗余_，应用部署在多台服务器上同时提供访问，数据存储在多台服务器上互相备份，任何一台服务器宕机都不会影响应用整体使用，也不会导致数据丢失。

    对于_应用服务器_，多台应用服务器通过负载均衡设备组成一个集群共同对外提供服务，这样某一台服务器宕机只要把请求切换到其他服务器就可实现应用高可用，但是有一个前提是应用服务器上不能保存请求的会话信息，
否则服务器宕机，会话丢失，即使将用户请求转发到其他服务器上也无法完成业务办理。

    对于_存储服务器_，由于其上存储着数据，需要对数据即使备份，当存储服务器宕机将数据访问请求到其他存储服务器上，并进行数据恢复以保证继续有服务器宕机的时候数据仍可用。

    除了运行环境，网站的高可用还需要软件开发过程的质量保证，通过预发布验证，自动化测试，自动化发布灰度发布等手段，减少故障引入线上环境的可能。

    衡量一个系统架构设计是否满足高可用的目标，就是假设系统中任何一台或多台服务器宕机或者出现各种不可预期的问题时，系统整体依然保证可用。

#### 3.3 伸缩性
     大型网站需要面对大量用户的高并发访问和存储海量数据，所谓伸缩性是指不断向集群中加入服务器的手段来缓解不断上升的用户并发访问压力和不断增长的数据存储需求。

     衡量系统伸缩性主要标准是是否可以提供多台服务器构建集群，是否容易添加服务器，加入服务器是否可以提供和原来的服务器无差别的提供服务，集群中的服务器总量是否有限制。

     对于_应用服务器_，只要服务器上不保存数据，所有服务器都是对等的，通过使用合适的负载均衡设备就可向集群中不断加入服务器。
     
     对于_缓存服务器_，加入新服务器可能导致缓存路由失效，进而导致集群中大部分缓存数据无法访问，需要改进缓存路由算法保证缓存数据的可访问性。

     关系数据库虽支持数据复制，主从热备等机制，但很难做到大规模集群的可伸缩性，因此关系数据库的集群伸缩性方案必须在数据库之外实现。通过路由分区等手段将部署到多个数据库的服务器组成一个集群。

     至于nosql数据库产品，由于其天生是为海量数据而生，因此其对伸缩性的支持通常都非常好，可以做到在较少运维参与的情况下实现集群规模的线性伸缩。

#### 3.4 扩展性
     扩展性注重网站的功能需求，设计网站需要考虑设计网站的架构使其能够快速响应需求变化，使网站可扩展；
     主要评价标准是扩展产品，对现有产品尽量透明无影响，产品之间少耦合，实现新功能对旧有的产品和功能不受牵连影响。
     
     网站可伸缩性主要手段是事件驱动架构和分布式服务。
     
    事件驱动架构在网站中通过消息队列实现，将用户请求和其他业务事件构造成消息发布到消息队列，消息的处理者作为消费者从消息队列中获取消息进行处理，消息产生和消息处理分离开来，可以透明地增加消息生产者任务或新消息消费者任务，降低耦合度。
    
    分布式服务在扩展性方面主要是将业务和可复用的服务分离开，通过分布式服务框架调用可复用的基础服务。
    大型网站还通过提供服务（即api接口）吸引开发者，扩展自身网站业务和开发周边产品。     

#### 3.5 安全性
    保证网站对现在的和潜在的攻击和危险有自身很好的防御系统。

#### 3.6 小结
   **_性能，可用性，伸缩性，扩展性和安全性是网站架构的最核心的几个要素，这几个要素解决了大型网站架构设计的大部分挑战也克服了。
接下来第二章围绕着5个架构要素组织说明_**。



## 第二章 架构


### 4.瞬时响应 ：网站的高性能架构

#### 4.1 网站性能测试
#####  1. 不同人眼中看到的性能点是不一样的，用户看到的是鼠标点击到返回响应的效果；开发人员侧重系统吞吐，并发处理能力等性能，运维人员看到的是基础设施性能和资源利用率。
#####  2. 性能测试指标
    1. 响应时间 ， 指应用发起请求到最后响应数据的时间。直观反映了系统的“快慢”。测试过程中通常测试程序发起以万记的请求，再计算平均响应时间。
    
    2. 并发数 ， 指系统能同时处理的请求的数目，这个数字也反映了系统的负载特性，对于网站而言，并发数即并发用户数。
     在网站设计初期，产品和运营就需要规划不同发展阶段用户数，依次为基础，推算在线用户和在线并发用户，这些指标是系统非功能设计的重要依据。

    3. 吞吐量 ， 指单位时间系统能处理的请求数量，对于网站，可以用“请求数/秒”or “页面数/秒”等来衡量，常用衡量指标有TPS(美妙事物数),HPS(美妙http请求数），QPS(每秒查询数)等，

    4. 性能计数器 , 描述服务器或操作系统性能的重要数据指标，对其进行监控，入股超出阀值对运维和开发人员报警。
#####  3.性能测试方法
  * 性能测试    对系统加压力，测试是否能在资源可接受范围内，达到性能预期。
  * 负载测试    对系统施压，直到某项资源呈饱和状态，此时如果再加压，系统处理能力不增反降
  * 压力测试    测试系统奔溃临界状态，获得系统最大的压力承受能力。
  * 稳定性测试  在不同环境，时间，压力下，更好的模拟了生产环境，测试系统的稳定性
     所谓的增加压力，在系统测试环境下即增加测试程序的并发请求数。前三者压力测试压力不断增加，性能测试遵循抛物线规律，x轴为系统资源， y轴为吞吐量；系统的绝大部分使用场景在性能测试范围内；
#####  4. 性能优化策略
  1.性能分析
     排查网站性能瓶颈，检查请求处理各个环节的日志，分析那个环节响应时间不合理，超过预期；然后检查监控数据，排查分析影响性能的主要因素是内存，磁盘，网络，还是CPU，还是代码问题，架构设计问题。或是系统资源确实不足。
  2.性能优化
     定位具体问题后，需要进行性能优化，根据网站分层架构，分为web前端性能优化，应用服务器性能优化，存储服务器性能优化。



####  4.2 web前端性能优化
>> web前端指网站业务逻辑之前的部分，包括浏览器加载，网站视图模型，图片服务，CDN服务等。 主要优化手段有优化浏览器访问，使用反向代理,CDN等；

##### 4.2.1 浏览器访问优化
   1. 减少http请求 
     http请求是无状态的应用层协议，每次http请求都要建立通信链路，进行数据传输，而在服务器端，每个http请求都要创立独立的线程去处理，开销很昂贵，可减少http请求数目有效提升访问性能。
   2. 使用浏览器缓存
     一些静态资源图片，css,js可以缓存，通过设置http头的cache-control,expires属性，设定浏览器缓存，时间可以自定义。 有时候更新js文件，此时需要跟新文件名，生成一个新的js文件更新到HTML文件的引用中（解决缓存js的问题）。
     使用浏览器缓存策略的网站在更新静态资源时，应采用批量更新方法，挨个批量更新每个文件。防止用户浏览器大量缓存失效。
   3. 启用压缩
     启用压缩，对文本文件html,css,js压缩效率达80%以上，适当使用，会增大浏览器和服务器压力。
   4. css放页面最上面，js放最下面
     css在下载完全部css后才对整个页面渲染，js则是浏览器在加载js后立即执行，有时会造成页面卡死。     
   5. 减少cookie传输
     cookie会包含在每次请求和响应中。因此cookie不宜大，另外请求静态资源如css,js发送cookie没意义，可考虑将静态资源放到独立静态服务器上。

##### 4.2.2 CDN加速
     cdn部署在机房，相当于缓存，距离用户近，一般将静态资源，访问频率高的资源放到缓存服务器上。
     
##### 4.2.3 反向代理
     传统代理位于浏览器一侧，可发送浏览器的请求给网络服务器；代理服务器在服务端一侧，可接受用户http请求，分发给不同服务器；
     反向代理服务器可提供静态资源的缓存和一些常用热门动态资源的缓存，减轻服务器压力。
     此外，反向代理具有负载均衡的功能，通过负载均衡的应用集群可提升系统总体处理能力，提升系统并发情况下性能。
#### 4.3 应用服务器性能优化
   应用服务器是处理网站业务的服务器，网站的业务代码部署在这里，同样是网站最复杂，变化最多的地方，优化手段主要是缓存，集群，异步等。
##### 4.3.1 分布式缓存
  >网站性能优化第一定律，优先考虑使用缓存优化性能。

     回顾网站架构演化历程，网站遇到瓶颈第一想到的解决方案是用缓存，整个网站应用中，缓存无处不在，既存在于浏览器也存在应用服务器和数据库服务器，既可对数据缓存也可对文件缓存，对页面片段缓存。
   1. 缓存的基本原理
      缓存存储在访问速度较高的介质中，访问速度快，减少访问时间，另一方面缓存失计算过的数据，减少计算时间。 
      缓存的本质是一个内存hash表。网站应用中，数据缓存以一对key,value的形式存储在内存hash表中； hash表的数据读写时间复杂度为O(1);
      换存主要存放那些读写比很高，又很少变化的数据，如商品类目，组织机构，热门词搜索列表，热门商品信息等。 应用程序度读数据先从缓存读取，读取不到再去数据库读取并缓存到缓存中；
      网站数据访问遵循28定律，所以将20%的数据缓存起来，可很好的改善系统性能，提高读取速度，减低存储访问压力。

  2. 合理使用缓存
     由于缓存使用内存作为介质，内存资源很宝贵，所以频繁修改的数据，没有热点的访问都不应该作为缓存。
     一般会对缓存的数据设置失效时间，一旦超时，就需要重新加载数据库；因此缓存数据和实际被修改数据有一定的时间差，当然可以修改数据时立即更新缓存，不过这也会带来更多系统开销和事物一致性问题。
     缓存可用性：
     由于网站规模越来愈大，缓存数据量很大，而缓存一旦失效，要求数据能重新冲数据库里读取出来，此时如果数据库承受不住压力，就会宕机，称为缓存雪崩。
     分布式缓存服务器集群：
     通过分布式缓存服务器集群，将缓存数据分布到集群多台服务器上可在一定程度上改善缓存的可用性。若一台缓存服务器宕机，只有部分缓存数据丢失，再去数据库获取，数据库可以承受这个压力。

**产品**
>>产品设计之初就有一个明确定位，实现什么功能，什么是产品不提供的特性。 产品在漫长的生命周期可能会遇到形形色色的诱惑和各种困难左右产品的方向， 什么都想做的产品，最后有可能成为一个失去生命力的四不像；

     缓存预热：
     缓存存放的是热点数据，使用LRU(最近最久未使用算法)，新启动的缓存没有数据，在重建缓存数据过程中是系统的性能和数据库负载都不太好，因此在缓存系统启动时就可以吧热点数据加载好，这个手段叫做缓存预热；对于一些元数据可在启动时加载数据库中的数据到缓存预热；
     缓存穿透：
     如果遇到恶意攻击，持续访问冷数据，这样所有请求都落到数据库服务上，容易对数据库造成压力甚至崩溃，一个简单的对策是将不存在的数据也缓存起来（value=null）;
  3.分布式缓存架构
     分布式缓存失指缓存部署在多个服务器组成的集群中。以集群的方式提供缓存服务，其架构方式有2种，一种是以jboss cache为代表的需要同步更新的分布式缓存，另一种是以memcached为代表的不互相通信的分布式缓存。
     
     jboss cache在分布式缓存服务器上保持缓存同步，某台服务器更新时，其他服务器保持update，delete；通常将缓存和应用程序部署在同一台服务器上，因此其限制性也是很明显的，首先缓存数据受限于单一服务器内存空间，其次集群规模较大时，缓存更新时要通知所有服务器，代价很大；
     因此jboss cache这种方案更多见于企业应用系统中，而很少在大型网站使用。

     大型网站需要缓存数据量比较大，可能需要TB级别的内存做缓存，需要另一种分布式缓存，Memcached采用一种集中式的缓存集群管理，也被称作互不通信的分布式架构方式。缓存与应用分离部署，缓存系统部署在一组专门的服务器上，应用程序通过一致性hash等路由算法选择缓存服务器远程访问缓存数据，
     缓存之间不相互通信，缓存集群的规模可以很容易实现扩容，具有良好的可伸缩性。
  4. Memcached
     memcached曾一度是网站分布式缓存的代名词，被大量网站使用，其简单的设计、优异的性能，互不通信的服务器集群，海量数据可伸缩的架构令架构师们趋之若鹜。
     
     虽然今年来许多NoSql产品层出不穷，在数据持久化、支持复杂数据机构，甚至性能方面有许多产品由于memcached，但memcached由于其简单，稳定，专注的特点，仍在分布式缓存领域占据重要地位。

    1. 简单的通信协议，通信协议有tcp,udp,http协议，通信序列化协议有xml,json等来传数据，使通信的两方能互相识别。memcached使用tcp协议通信，其序列化协议是自定义的文本协议，非常简单。
    2. 丰富的客户端程序，memcached的通信协议非常简单，能支持该协议的客户端都可以和memcached服务器通信，几乎支持所有主流的网站编程语言，如java,c/c++,perl,php,python,ruby等。
    3. 高性能的网络通信，memcached服务端通信模块基于libevent,一个支持事件触发的网络通信程序库，libevent在稳定的长连接方面的表现正式memcached所需要的。
    4. 高效的内存管理，最小内存块是chunk，固定大小，然后一组chunk组成slab,一组slab组成slab_class, 采用LRU算法释放最近最久未被访问的内存； *这种方式会带来内存浪费问题，如果启动参数配置不合理，浪费会更加惊人！使用需注意。*
    5. 互不通信的服务器集群架构，正是这个特性使memcached从Jboss cache, oscache等众多分布式缓存产品脱颖而出，满足网站对海量缓存数据的需求，而其客户端路由算法一致性hash更成为数据存储伸缩性架构设计的经典模式（第6章）。
   实际也正是集群内服务器互不通信使得集群可以做到几乎无限制的线性伸缩，这也是目前流行的许多大数据技术的基本架构特点。

##### 4.3.2 异步操作
 > 使用消息队列将调用异步化，可改善网站的扩展性，事实上，使用消息队列还可以提升网站系统的性能。
 >> 消息队列服务器，未使用时：1.客户端发起请求-->网站应用服务器-->数据库服务器
                    使用时：  2.客户端发起请求-->网站应用服务器-->消息队列服务器-->数据库服务器

     在不使用消息队列时，客户端请求数据直接写入数据库，在高并发情况下会对数据库造成很大压力，同事响应延迟加剧。在使用消息队列后，用户请求的数据发送给消息队列后立即返回，再由消费队列的消费者进程（通常情况下，该进程通常独立部署在专门的服务器集群上）从队列中获取数据，异步写入数据库。由于消息队列服务器处理速度远快于数据库（消息队列服务器比数据库具有更好的伸缩性），因此用户的响应延迟也可得到有效改善。
     消息队列有很好的流量削峰作用。通过异步处理，将短时间高并发产生的事务消息存储在消息队列中，从而削平高峰期的并发事务。
     需要注意的是，由于数据写入消息队列后立即返回给用户，数据在后续的业务校验，写数据库操作可能失败，因此在使用消息队列进行业务异步处理后，需要适当修改业务流程进行配合，如订单提交后，
    订单数据写入消息队列，不能立即返回用户订单提交成功，需要在消息队列的订单消费者进程真正处理完该订单，甚至商品出库后，再通知电子邮件或sms消息通知用户订单成功，以免交易纠纷。

##### 4.3.3 使用集群
     在网站高并发访问的场景下，使用负载均衡技术为一个应用构建一个由多台服务器组成的服务器集群，将并发访问请求分发到多台服务器上，减轻单一服务器压力，提高响应速度。
     负载均衡过程； 用户浏览器-->负载均衡服务器-->web服务器集群

##### 4.3.4 代码优化
     网站的业务逻辑实现代码主要部署在应用服务器上，需要处理复杂的并发事务。下面主要关注几个优化方面：
      1. 多线程
       多用户访问时网站的基本需求，大型网站的并发用户数会达到数万，单太服务器的并发用户也会达到数百。CGI编程时代，每个用户请求都会创建一个独立的系统进程去处理。由于线程比进程更轻量，更少战友系统资源，切换代价更小，所以目前主要的web应用服务器都采用多线程的方式响应并发用户请求，因此网站开发天然就是多线程编程。
      从资源利用的角度看:  使用多线程主要是为了更好的利用多核cpu,当前线程进行io处理，会被阻塞释放cpu以等待io操作完成，io(不管是磁盘id还是网络id)通常需要较长时间。cpu可以调度其他线程进行处理。
        线程启动数：   启动线程数=[任务执行时间/(任务执行时间-IO等待时间)]*CPU内核数。
            最佳启动线程数和CPU内核数量成正比，和IO阻塞时间成反比。如果任务都是cpu计算型任务，那么线程数量最多不超过cpu内核数。因为启动再多线程，CPU也来不及调度；相反如果是任务需要等待磁盘操作， 网络响应，那么多启动线程有助于提高任务并发度，提高系统吞吐能力，改善系统性能。
        线程安全问题：  多线程使用另外一个问题是线程安全问题，即多线程并发对某个资源进行修改，导致数据混乱。这也是缺乏经验的网络工程师最容易犯错的地方。线程安全bug难以测试和重现，网站故障中许多“灵异事件”都和多线程并发问题有关。对网站而言，每一行代码都会被多线程执行，因为用户的请求是并发提交的，所有的资源----对象，内存，文件，数据库，乃至另一个线程都可能被多线程并发访问。
       
        编程中，解决线程安全的主要手段有以下几点。
        * 将对象设计成无状态对象，java中servlet就是无状态对象
        * 使用局部对象， 即在方法内部创建对象，这样对象会被每个进入方法的线程创建。除非线程有意识地将这些对象传递给其他线程，否则不会出现对象被多线程并发访问的清形。
        * 并发访问资源时使用锁， 即多线程访问资源时，对资源加锁，使多线程并发操作转化为顺序操作，避免资源被并发修改。
     2. 资源复用
        系统运行时，要尽量减少那些开销很大的系统资源的创建和销毁，如数据库连接、网络通信连接、线程、复杂对象等，资源复用主要有两种模式：单例singleton和对象池object pool。 
        目前web开发中主要使用贫血模式，从service到dao都是些无状态对象，无需重复创建，使用单例模式就自然而然了，事实上，java开发常用的对象容器spring默认构造的对象都是单例的，spring的单例是spring容器管理的单例，而不是单例模式构造的单例。
        对象池模式通过复用对象实例，减少对象创建和资源消耗。实际使用中，数据库连接基本使用连接池（connection pool）方式。数据库连接对象创建好以后，将连接对象放入对象连接池中，应用程序要连接时，就从对象池中获取一个空闲的连接使用，使用完毕再将该对象归还到对象池中即可，不需要创建新的连接。
        前面说过，对于每个webhttp请求，web应用服务器都需要创建一个独立的线程去处理，这方面，应用服务器也采用线程池的方式。 本质上连接池，线程池都是对象池。池管理方式基本相同。
     3. 数据机构
        求hashcode过程中，相似字符串hashcode可能比较相近，在某些应用场景是不符合规范的，此时可以对原本的字符串取信息指纹，再对指纹求hashCode,
     4. 垃圾回收
        如果web应用运行在jvm等具有垃圾回收功能发的环境中，那么垃圾回收可能对系统性能有巨大影响，理解垃圾回收机制有助于程序优化和参数调优，以及编写安全的代码。
        java JVM应该根据系统业务特点和对象生命周期，合理设置young generation和old generation大小，尽量减少full GC,事实上，某些web应用在整个运行期间可以做到从来不进行full GC。

#### 4.4  存储性能优化      
        在网站应用中，海量数据读写对磁盘访问造成很大压力，缓存虽然可以解决一部分问题，但是磁盘仍然是系统最严重的瓶颈。磁盘存储着网站最重要的数据，磁盘的可用性和容错性也至关重要。   

##### 4.4.1 机械硬盘 vs. 固态硬盘
        机械硬盘是目前最常用的一种硬盘，通过磁头臂带动磁头到指定的磁盘位置访问数据。由于每次访问数据需要磁头臂，因此机械硬盘在数据连续访问（要访问的数据存储在连续的磁盘空间上）和
随机访问（要访问的数据存储在不连续的磁盘空间）时，由于移动磁头臂的次数相差巨大，性能表现也非常大。
        固态硬盘称SSD硬盘或Flash硬盘，这种硬盘没有机械装置，数据存储在可持久记忆的硅晶体上，因此可以向内存一样快速随机访问。而且ssd具有更小的功耗和更少的磁盘震动与噪声。
        在网站应用中，大部分数据访问都是随机的，这种情况下ssd具有更好的性能表现。目前ssd硬盘还不太成熟，可靠性，性价有待提升，但随着SSD工艺水平的提高，逐步替代传统机械硬盘是迟早的事。

##### 4.4.2 B+树 vs. LSM 树
	 B+ 树： 关系型数据库
        上一节提到，由于传统的机械磁盘具有快速顺序读写、慢速随机杜尔西的访问特性，这个特性对磁盘存储结构和算法的选择影响甚大。
        为了改善数据访问特性，文件系统或数据库系统通常会对数据排序后存储，加快数据检索速度，这就需要保证数据在不断更新、插入、删除后依然有序，传统关系型数据库的做法是使用b+树。
        B+树是一种专门针对磁盘存储而优化的N叉排序树，以树节点为单位存储到磁盘中，从根节点开始查找所需数据所在的节点编号和磁盘位置，将其加载到内存中然后继续查找，指导找到所需的数据。
        目前数据库多采用2级索引的b+树，树的层次最多3层，因此可能需要5此磁盘访问才能更新一条记录。（3此磁盘访问获得数据索引及行ID，然后再进行一次数据文件读操作及一次数据文件写操作）。
        但是由于每次磁盘访问都是随机的，而传统机械硬盘在数据随机访问时性能较差，每次数据访问都需要多次访问磁盘影响数据访问性能。

        LSM树：NoSql产品
        目前许多NoSql产品采用LSM树作为主要数据结构。

        LSM树可以看做是一个N阶合并树，数据写操作都在内存进行，这些数据在内存中仍然是一棵排序树，当数据量超过预定的内存阀值时，会将这颗排序树和磁盘上最新的排序树合并。当这棵排序树的数据量也超过设定
阀值后，和磁盘上下一级的排序树合并。合并过程中会用新的数据覆盖就的数据（或记录为不同版本）。
        在需要进行读操作时，首先会从内存中的排序树读数据，如果内存没有才去磁盘中找。
        在LSM树上进行一次数据更新不需要磁盘访问，在内存即可完成，速度远快于B+树。当数据访问以写操作为主，读操作则集中在最近写入的数据上时，使用LSM数可极大程度地减少磁盘访问次数，加快访问速度。

##### 4.4.3 RAID VS. HDFS
        RAID 廉价磁盘冗余阵列技术主要是为了改善磁盘的访问延迟，增强磁盘的可用性和容错能力。目前服务器级别的计算机都支持插入多块磁盘（8+），通过使用RAID技术，实现数据在多块磁盘上并发读写和数据备份。
        RAID技术可以通过硬件实现，比如专用的RAID卡或者主板直接支持，也可以通过软件实现。RAID技术在传统关系型数据库以文件系统中应用比较广泛，但是在大型网站比较喜欢使用的是NoSql.以及分布式文件系统
中，RAID技术却遭到冷落。

        例如在HDFS（hadoop分布式文件系统）中，系统在整个存储集群的多台服务器上进行数据并发读写和备份，可以看作在服务器集群规模上实现了类似RAID的功能，因此不需要磁盘RAID。
        HDFS以块（BLOCK）为单位管理文件内容，一个文件被分割为若干个BLOCK，当应用程序写文件时，每写完一个BLOCK，HDFS会自动将此BLOCK备份到另外2台机器上。相当于实现了RAID复制备份功能。
        当对文件进行处理计算时，通过MapReduce并发计算任务框架，可以启动多个计算子任务（MapReduce Task）,同时（并发读）读取多个BLOCK，并发处理，相当于实现了RAID0的并发访问功能。
   _HDFS配合MapReduce等并行计算框架进行大数据处理时，可以在整个集群上并发读写访问所有的磁盘，无需RAID支持。_


####  4.5 小结
        网站性能优化技术是在网站性能遇到问题时的解决方案。而网站性能问题很多事在用户高并发访问时产生的，所以网站性能优化的主要工作是改善并发用户访问情况下的网站响应速度。
        网站性能对用户而言就是一种主观感受，性能优化目的是让用户感觉很快，离开这个目的追求技术，是舍本逐末，架构师需要明白。
        技术是为业务服务的，性能优化也需要全面考虑，综合权衡效果，做出选择方案。
 >前沿技术总是出现在前沿业务领域，新技术的出现又会驱动企业开展新的业务。亚马孙等互联网公司利用自己的技术优势进军企业级市场，以技术驱动业务，开展云计算，SaaS等新兴IT业务。逐步蚕食IBM,HP,
ORACLE等传统软件巨头的市场。

###  5. 万无一失：网站的高可用架构

#### 5.1 网站可用性的度量与考核
        网站的页面能呈现在最终用户面前，需要经历很多环节，要保证一个网站永远完全可用几乎是一件不可能完成的使命。

##### 5.1.1 网站可用性度量
       对于网站而言，达到2个9 99%是基本可用。 4个9，99.99%是具有自动恢复功能的高可用。达到4个9或5个9不近是靠实力，责任心也需要一定运气。
目前qq服务可用性是4个9，而twitter网站可用性不足2个9.所以常用twitter用户可能会遇到过服务不可用的鲸鱼页面。

##### 5.1.2 网站的可用性考核
       可用性考核会分一个层级，A,B,C等级别区分故障，落实责任。另外不同公司在不同发展期侧重点不同，对可用性要求的程度也有差别。

#### 5.2 高可用的网站架构
       典型的分层模型即为应用层、服务层、数据层。各层之间相对独立，应用层负责业务逻辑处理，服务层负责提供可复用的服务；数据层负责数据的存储与访问。小型网站部署时，通常将应用和服务层部署在一起，
数据层另外部署。大型网站架构中，划分的粒度会更小，更详细，结构更复杂。
       
       大网站中，不同的业务产品会部署到不同的服务器集群上，例如“某站”的文库、贴吧、百科等属于不同的产品，部署在格子独立的服务器集群上，互不相干。这些产品又依赖一些共同的复用业务，如注册登录服务，
session管理服务、账户管理服务等，这些可复用的业务服务也各自部署在独立的服务器集群上。 至于数据层，数据库服务、文件服务、缓存服务、搜索服务等数据存储于访问服务都部署在各自独立的服务器集群上。

       “某站”应用层（文库，贴吧，知道，百科），服务层（账户服务，session服务，登录服务），数据层（数据库服务，文件服务，缓存服务，搜索服务）；
       位于应用层的服务器通常为了应对高并发的访问请求，会通过负载均衡设备将一组服务器组成一个集群共同对外提供服务，当负载均衡设备通过心跳监测等手段监控到某台应用服务器不可用时，将其从
集群列表剔除，并将请求分发到集群中其他可用的服务器上，使整个集群保持可用，从而实现高并发。
       位于服务层的服务器情况与应用层类似，通过集群实现高可用，只是这些服务器被应用层通过“分布式服务调用框架”访问。分布式服务调用框架会在应用层客户端程序中实现软件负载均衡，并通过服务注册
中心对提供服务的服务器进行心跳监测，发现服务不可用，或新增服务，都会修改服务访问列表。
       位于数据层的服务器情况比较特殊，数据服务器上存储着数据，为了保证服务器宕机时数据不丢失，数据访问服务不中断，需要在数据写入时进行数据同步复制，将数据写入多台服务器上，实现数据冗余备份，
当数据服务器宕机时，应用服务将访问切换到有备份数据的服务器上。

       网站升级的频率很高，一周一次，甚至一天一次，所以架构需要考虑升级带来的服务器整体宕机问题。

#### 5.3 高可用的应用
       应用层主要处理网站应用的业务逻辑，因此有时也称作业务逻辑层，应用的一个显著特点是应用的无状态性。即每个应用实例（服务器）完全对等，不保存上下文信息，请求到任何服务器，处理结果是一样的。

##### 5.3.1 通过负载均衡进行无状态服务的失效转移
       不保存状态的应用给高可用的架构设计带来巨大便利，因为服务器是可随意替代的，对于应用服务器集群，实现服务器可用状态的实时监控、自动转移失败任务机制是负载均衡。
       负载均衡将流量和数据分摊到一个集群组成的服务器群，提高整体负载处理能力。开源免费的负载均衡软件和昂贵的负载均衡硬件都提供失效转移功能。

##### 5.3.2 应用服务器集群的session管理
       应用服务器的高可用架构设计主要基于服务无状态这一特性，实际上，业务总是有状态，要依赖状态。例如购物，社交网站，都需要记录近期状态。
       web应用中将这些多次请求修改使用的上下文对象称作会话（Session）,单机情况下，session可由部署在服务器上的Web容器（如Jboss）管理。在使用
负载均衡的集群环境中，由于负载均衡服务器可能会将请求分发到集群任何一台应用服务器上，所以保证每次请求依然能获得正确的session比单机要复杂的多。
       
       集群环境下，session管理主要有以下几种手段。
      1. session复制，简单的方式，在大型网站中核心应用集群就是数千台服务器，同时在线用户可达到数千万，复制的劣势很明显，不适用这种方案。
      2. session绑定，session绑定可以利用负载均衡的源地址hash算法实现，负载均衡服务器总是将来源于同一IP的请求分发到同一台服务器上，又称为会话黏滞，即固定（唯一服务器），但是这不符合对系统
高可用要求，所以实际也不适用。
      3. 利用cookie记录session，早期的企业应用系统使用C/S架构，一种管理session方式是将session记录放在客户端，每次请求服务器时，将session放在请求中发给服务端，服务端再将处理完请求后再将修改后的
session响应给客户端。而网站没有客户端，但是可以利用浏览器支持cookie记录session； 利用cookie记录session也有一些缺点，比如受cookie大小限制，用户可以关闭cookie，但是cookie简单易用，可用性高，支持
应用服务器线性伸缩，而大部分应用需要cookie
比较小，因此事实上，许多网站都或多或少地使用cookie记录session；
      4. session服务器
         综合以上问题，有没有一种可用性高，伸缩性好，性能还不错，对信息大小有没有限制的服务器集群session管理方案呢？
         答案就是session服务器。利用独立部署的session服务器（集群），同一管理session。应用服务器每次读写session时，都访问session服务器。

         对于有状态的session服务器，一种比较简单的方法时利用分布式缓存、数据库等，在这些产品的基础上进行包装，使其符合session的存储和访问要求。如果业务场景对session管理有比较高的要求，比如利用
session服务集成单点
登录（SSO），用户服务等功能，则需要开发专门的session服务管理平台。

#### 5.4 高可用的服务
        可复用的服务模块为业务产品提供基础公共服务，大型网站中这些服务通常都独立分布式部署，被具体应用远程调用。同样是无状态的服务，因此可以使用类似负载均衡的失效转移策略实现高可用服务。

       除此之外，具体实践中，还有以下几点高可用的服务策略：
        1. 分级管理
          运维上将服务器进行分级管理，核心应用和服务优先使用更好的硬件。同时服务器部署上也进行必要的隔离，避免故障的连锁反应。
        2. 超时设置
          由于服务器宕机，线程死多等原因，可能导致应用程序对服务端的调用失去响应，进而导致用户请求长时间得不到响应，还占用应用程序的资源。此时可以在应用程序设置超时的事件，一旦超时，通信框架抛出异
常。应用程序重新选择调用方式。
        3. 异步调用
          应用对服务的调用通过消息队列等异步方式完成，避免一个服务失败导致整个应用请求失败的情况。
          当然不是所有服务调用都可以异步调用，对于获取用户信息这类调用，还有必须确认调用成功才能继续下一步操作的应用也不合适使用异步调用。
        4. 服务降级
          网站访问高峰期，服务可能由于大量并发调用而性能下降，严重导致服务宕机。为保证核心功能可用，采用降级的手法减轻服务压力。
          如：拒绝服务，拒绝优先级地的应用的调用，减少服务调用并发数，或者随机拒绝部分请求调用，节约资源，如twitter比较喜欢随机拒绝服务，经常有用户看到自己访问的页面报错，而身边的人能用，再刷新一下就好了。
              关闭功能，关不部分不重要的功能，减少系统开销，如淘宝双11促销中，系统繁忙时关闭“评价”，“确认收货”等非核心服务，保证核心交易服务顺利完成。
        5. 幂等性设计
          即在服务层保证服务重复调用和调用一次产生的结果相同，即服务具有幂等性。 
          有的服务天然具有幂等性，如性别设置为男，不管设置多少次也没关系，而转账交易等操作，问题就比较复杂，需要通过交易编号等信息进行服务调用有效性校验，只有有效的操作才能进行。

#### 5.5 高可用的数据
        对网站而言，数据时最宝贵的财富，硬件可用购买，软件可用再重写，数据是历史积累下来的重要内容，（用户数据，交易数据，商品数据），一旦出问题，打击是毁灭性的。
        不同于高可用的应用和服务，由于数据存储服务器上保存的数据不同，当某台服务器宕机的时候，数据访问请求不能任意切换到集群中其他机器上。
        
        保证数据存储高可用的主要手段是数据备份和失效转移机制。
        数据备份是保证数据有多个副本，不丢失。失效转移是一个副本失效了，可以快速切换数据的其他副本访问。
        通过逻辑或物理分区的方式将每个应用的缓存部署在多台服务器上，任何一台服务器宕机引起的缓存失效都只影响应用缓存数据的一小部分，不会对应用性能和数据库负载造成太大影响。

##### 5.5.1 CAP原理
        在讨论高可用的数据服务架构之前，为了保证数据的高可用，网站通常会牺牲另一个也很重要的指标：数据一致性。
        高可用的数据有如下几个层面的含义。
       * 数据持久性：保证数据可持久存储，各种情况下不会出现数据丢失的问题，不但在写入数据时需要写入持久性存储，还需要将数据备份多个副本保存。
       * 数据可访问性：在多个备份副本的情况下，如果一个数据存储设备损坏，需要将数据访问切换到另一个数据存储设备上，这个过程要很快速完成（客户没感知），否则客户等待时间数据就是不可访问的。
       * 数据一致性：数据写入副本过程中，网络，服务器等某方面出现故障，数据就可能不一致。要保证应用可用，必须保证分布式处理系统的高可用性，此时数据不一致通常出现在系统
高并发写操作或集群状态不稳时，应用系统需要对分布式数据处理系统的数据不一致性有所了解并进行某种意义上的补偿和纠错。避免数据不正确。
         数据一致性分为： 数据强一致，数据用户一致，数据最终一致。网站通常会综合各种场景，使存储系统达到用户一致，保证最终用户访问数据的正确性。

##### 5.5.2 数据备份
         数据冷备份廉价，但不能保持实时更新数据，有延迟性。
         数据热备份：  异步热备份和同步热备份。
         * 异步热备份即主从同步（多分数据副本写入操作异步完成，应用程序收到数据服务系统的写入操作成功响应时，只写成功一份）；数据写入时，由主存储服务器的写操作代理模块将数据写入本机存储系统后立
即返回写操作成功，再又异步线程将写操作数据同步到从存储服务器。
         * 同步热备具体实现时，为了提高性能，在应用程序客户端并发向多个存储服务器同时写入数据，然后等待所有存储服务器都返回操作成功的响应后，再通知应用程序写操作成功。
         传统的企业级关系型数据库系统几乎都提供了数据实时备份的机制，而一开始就是为了大型网站设计的各种NoSql数据库更是将数据备份机制作为产品最主要的功能点之一。
         * 关系数据库热备机制就是常说的Master-Salve同步机制。 关系数据库热备份机制就是通常所说的Master-Salve同步机制，Master-Salve机制不但解决了数据备份问题，还改善了数据库系统的性能，解决负载压力。

##### 5.5.3 失效转移
       若数据服务器集群中任何一台服务器宕机，那么应用程序针对这台服务器的所有读写操作都需要重新路由到其他服务器，保证数据访问不会失败，这个过程叫失效转移。
       失效转移由3部分组成：失效确认、访问转移、数据恢复。

#### 5.6 高可用网站的质量保证
       本节介绍网站为了保证线上系统的可用性而采取的一些与传统软件开发不同的质量保证手段。

##### 5.6.1 网站发布
       网站发布频繁，大型网站可能每周都要发布几次更新，而重新部署新的应用事实上与服务器宕机效果相当；
       发布网站通常使用发布脚本来完成发布。关闭负载均衡服务器上一台或小批服务器路由，关闭应用，同步代码，启动应用，打开负载均衡服务器上这些服务器路由；然后依次循环此步骤，直到最后所有发布完成。

##### 5.6.2 自动化测试
       目前大部分网站都采用web自动化测试技术，使用自动化脚本或工具完成测试。比较流行的web自动化测试工具是thoughtWords开发的selenium.selenium运行在浏览器中，模拟用户操作进行测试。因此selenium可以
同时完成web功能测试和浏览器兼容测试。
       大型网站通常也会开发自己的自动化测试工具，可以一键完成系统部署，测试数据生成、测试执行、测试报告生成等全部测试过程。许多网站测试工程师的编码能力毫不逊于软件工程师。

##### 5.6.3 预发布验证
       即使经过严格测试，软件部署到线上服务器后依然可能经常出现各种问题。主要原因是测试环境和线上环境并不相同。特别是应用需要依赖其他服务如数据库，缓存，公共业务服务等。以及一些第三方服务，
如电信短信网关，银行网银接口。也许是数据库表结构不一致，也许是接口变化导致通信失效，也许是配置错误导致连接失败，或者是服务线上环境还没有准备好。这些问题都可能导致应用故障。
       因此在网站发布是，通常预发布到机器上，开发和测试进行预发布验证，执行典型的业务流程才会正式发布。
       “预发布服务器”是一种特殊用途的服务器，他和线上正式服务器唯一不同就是没有配置在负载均衡服务器上，外部用户无法访问。预发布服务器可以同步代码到正式应用服务器集群上，预发布服务器与
正式服务器使用相同的物理环境，可能在同一个机架上，使用相同的线上配置，依赖相同的外部服务，网络工程师通常在自己的开发用计算机上配置hosts文件绑定域名ip关系直接使用ip地址访问预发布服务器，进行测试。
##### 5.6.4 代码控制
