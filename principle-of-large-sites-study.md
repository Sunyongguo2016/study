# 大型网站技术架构核心原理与案例分析  
> --阿里“教授” 李智慧
principle of large sites

###  1. 大型网站架构演化
#### 1.2大型网站架构演化发展历程

 >> *本书1.2部分架构的图例很清晰重要*
 
    1. _初始阶段_，  一台服务器，应用程序，文件，数据库都在一起；一个基于所有开源软件的小网站建立；
     2. _用户增加_， 应用服务和数据服务分离  应用程序在一台服务器，需要处理复杂的业务逻辑，所以需要CPU又快又强大； 数据库在一台服务器，需要快速磁盘检索和数据缓存，因此需要更快的硬盘和更大的内存； 文件服务器在另一台服务器，需要存放上传的文件，需要更大的硬盘。
    3. _使用缓存改善网站性能_，  由于用户增多，数据库压力太大导致延迟访问，由此：数据访问遵循2/8法则，所以想到使用缓存。 缓存分2种，一种应用服务器本地缓存，这种受服务器内存限制，且会与应用服务器争内存；另一种是使用远程分布式集群缓存，部署大内存服务器作为缓存服务器，可以在理论上做到不受内存容量限制的缓存服务；
    4. _使用应用服务器集群改善网站的并发处理能力_，使用集群是网站解决高并发、海量数据问题的常用手段。 用户过于庞大，不要一味加大服务器内存，性能；应用服务器实现集群是网站可伸缩集群架构设计中较为简 单成熟的一种。
    此时通过负载均衡调度服务器，可将来自用户浏览器的访问请求分发到应用服务器集群中任何一台服务器上，压力增大的话在集群中加入更多服务器即可，使应用服务器的负载压力不再成为整个网站的瓶颈。
    5. _数据库读写分离_，  网站使用缓存后，绝大部分数据库操作访问都可以不通过数据库就能完成，但仍有一些写操作或缓存过期，缓存不命中的操作需要访问数据库。用户增大时，数据库又成为网站服务支持的瓶颈。
    大部分数据库提供主从热备功能，因此配置主从数据库关系，可以将一台数据库服务器数据更新到另一台服务器上，利用这个数据库特性实现读写分离。此时，通常在应用服务器端使用专门的数据访问模块，读写数据。
    6. _使用反向代理和cdn加速网站响应_
    国内复杂的网络环境，不同地区用户访问网站速度差别很大。加入网站响应主要有反向代理和CDN加速；2者都是经过负载均衡调度服务器请求的，CDN和反向代理基本原理都是缓存，cdn是从部署在网络提供商的机房服务器取缓存，反向代理从反向代理的服务器取真实应用服务器的缓存。
     使用CDN和反向代理目的都是尽早返回数据给用户，取缓存服务器的数据，一方面加快用户访问速度，另一方面减轻后端服务器的负载压力；
    7. _使用分布式文件系统和分布式数据库系统_。
     任何单一的服务器都满足不了大型网站持续增长的业务需求，数据库读写分离是拆分了2台服务器，随着数据增长，最终需要分布式数据库和分布式文件系统服务器。
    _分布式数据库是网站数据拆分的最后手段_，只有单表数据规模非常庞大才使用，不到不得已，网站更常用数据库拆分手段是业务分库，将不同业务的数据库部署在不同的物理服务器上。
    8. _使用noSql和搜索引擎_
    随着网站业务复杂化，对数据存储和检索需求也越来越复杂，网站需要采用一些非关系型数据库技术如NoSql和非数据库查询技术如搜索引擎。
    者2者都是源自互联网技术手段，对可伸缩的分布式特性具有更好的支持，应用服务器则通过一个统一的数据访问模块访问各种数据，减轻应用程序管理诸多数据源的麻烦。
    9. _业务拆分_    
    大型购物交易网站，会拆分各个业务模块，如商铺，订单，卖家，买家。分归不同的业务团队负责。
    10. _分布式服务_
     通过分布式服务调用共用业务服务（可复用业务连接数据库），来完成具体的业务操作。云计算平台已经作为一种基础资源出售，中小企业不用注重实现细节，直接租用服务即可。

###  2. 大型网站架构模式
_*大型网站架构思路：拆分，从横向纵向拆分，从逻辑上物理上拆分，拆分的粒度很细，在物理上实现微服务集群，远程协同调用工作，降低访问压力*_

>   我们通过学习掌握大型网站架构的一般思路和解决方案，以指导我们的架构设计 

>   为解决大型网站面临的高并发访问，海量数据处理，高可靠运行这些挑战，大型互联网公司提出许多解决方案以实现高性能，高可用，易伸缩可扩展安全等架构目标；

#### 2.1 网站架构模式
   1. 分层  *横向分思想* 各模块分层，例如视图层，业务层，持久层，各模块拆分，人员负责维护自己的模块，保证接口稳定即可；
       分层首先是用在规划软件清晰的逻辑结构便于开发，后来可以将不同层部署到不同服务器上，分层结构对网站支持高并发分布式方向发展至关重要，网站从小就应该分层。
    2. 分割  *纵向分思想*  网站越大，越需要纵向分割，比如在业务层分割，将粒度分割的很细，如购物，论坛，搜索，广告各模块，购物业务比较重还可以细分，如分割机票酒店业务，3C业务，小商品等等细的模块。
       这些模块不管是在逻辑上还是物理部署上，都是独立的。
    3. 分布式  分布式有自身的一些缺陷，如数据一致性，事物等的处理。
   * 常用分布式方案：分布式应用和服务（不同应用复用共同的服务，便于业务功能扩展）；
   * 分布式静态资源（动静分离）；
   * 分布式数据和存储（数据量p级别，一般分布存储，noSql产品一般也是分布式）； 
   * 分布式计算（业务的计算规模很庞大，如数据仓库数据分析统计，网站普遍使用Hadoop及其mapReduce分布式计算框架进行大数据量批处理计算（特点是移动计算而非移动数据，将计算程序分到数据所在位置以加速计算和分布式计算））
   * 此外，还有支持网站线上服务器配置实时更新的分布式配置，分布式环境下实现并发和协同的分布式锁；支持云存储的分布式文件系统等。
  4. 集群 
     集群是针对一部分用户集中访问的内容，做的相同应用的集群化部署，通过负载均衡设备对外提供服务。 集群提高系统的可用性，一方面提供备份，一方面解决并发压力。
  5. 缓存
     缓存就是将数据放在距离计算最近的位置以加快处理速度。
    * cdn 内容分发网络，部署在距离最近的运营商服务器，将一些常用的较少改变的数据缓存。 
    * 反向代理 反向代理，用户请求到达网络数据中心时，最先访问的是反向代理服务器，这里缓存了静态资源，不需要请求中心服务器就可返回数据给用户。
    * 本地缓存 应用服务器本地（内存）缓存热点数据，直接返回数据给请求。
    * 分布式缓存  大型网站缓存数据量大，缓存数据放到分布式集群。
  6. 异步
   * 系统解耦的一个重要手段是异步，单一服务器内部可通过多线程共享内存队列的方式实现异步，处在业务操作前面的线程将输出写入队列，后面的线程从队列读取数据进行处理。
   * 在分布式系统中，多个服务器通过分布式消息队列实现异步，分布式消息队列可看做是内存队列的分布式部署。
   * 异步队列是典型的生产者消费者模式。两者不存在直接调用，只要保持数据结构不变，彼此功能实现可以随意变化而不相互影响。
   * 异步消息队列有如下特性。
   1. 特高系统可用性，消费者宕机，生产者不影响工作；
   2. 加快网站响应速度 处在业务前端的生产者服务器处理完业务请求后，数据写入消息队列，不需要等消费者服务器处理即可返回，响应延迟减少
   3. 消除并发访问高峰 大流量访问时，使用消息队列，请求数据放入队列中，等待消费者服务器依次处理，不会对整个网站造成太大压力。
   4. 使用异步需注意场景，！
  7. 冗余 
     冗余及备份，对服务器备份形成集群，对数据定时备份，对数据库进行主从分离，实时同步热备份。 重要内容全球灾备数据中心。
  8. 自动化
     无人值守状况下网站可正常运行，目前大公司的自动化一般有 发布过程自动化，自动化代码管理，自动化测试，自动化安全监测，部署，自动化报警，失效回复等等。
     自动化贯穿整个网站开发以及运维过程。
  9. 安全
    * 例如 通过密码手机校验码进行身份验证，登录。 对登录，交易信息加密。网站使用验证码识别机器人防止滥用资源，对xss，sql注入等黑客攻击，进行编码转换等手段，对垃圾信息过滤，对交易等重要数据操作进行风险控制。

#### 2.2 架构模式在新浪微博的应用（_举例说微博具体怎么使用架构模式 完美_）
   _*新浪分三层部署*_

  1. 新浪微博从小网站lamp linux apache mysql php发展起来，现在系统分为三层，最下层是基础服务层，提供数据库，缓存，存储搜索等数据服务，以及其他一些
  基础的技术服务，这些服务支撑了新浪微博的海量数据和高并发访问，是整个系统的技术基础。
  2. 中间层是平台服务和应用服务层，新浪微博的核心是微博，关系和用户，他们被拆成独立的服务模块，通过依赖调用和共享基础数据构成了新浪微博的业务基础。
  3. 最上层是API和新浪微博业务层，由客户端和第三方应用通过调用api集成到新浪微博系统，共同组成一个生态系统。

  4. 这些被分层和分割后的业务模块和基础技术模块分布式部署，每个模块部署到一个独立的服务器集群上，通过远程调用方式相互依赖，新浪早期使用过MPSS技术，将
  多个应用部署到一台服务器，改变端口实现资源最大化利用，现在常用的方式是将物理机虚拟成多个虚拟机，再在虚拟机上部署应用，这样可以不改变端口部署应用。
  5. 新浪早期技术机构中，微博发布采用同步推模式，用户发布微博会立即将内容推送到关注人的推送列表中，这样明星用户发起微博会导致系统压力很大，延迟很慢；    后来改为异步推拉结合的方式，用户发表微博后系统将微博写入消息队列后立即返回，用户响应迅速，
  消息队列消费者任务将微博推送给当前在线的粉丝订阅列表中，非在线用户登陆后再根据关注列表拉去微博列表。
 
    由于微博刷新频繁，新浪微博使用多级缓存策略，热门微博和明星用户微博缓存在所有服务器上，在线用户的近期微博_缓存_在分布式缓存集群中，常见的刷微博操作，几乎全是缓存访问操作，可获得很好的系统性能。
    
    为提高系统整体可用性和性能，新浪微博启用了_多个数据中心_，这些数据中心既是地区用户访问中心，方便用户就近访问提高访问速度，也是数据冗余复制的灾备中心，所有用户和微博数通过远程消息系统在不同的数据中心之间_同步_，提升系统可用性。
    
    同时，新浪微博开发了一系列_自动化工具_，包括自动化监控，自动挂发布，自动化故障修复等。这些自动化工具可改善运维水平提高系统可用性。
 
    在_安全性_上，由于微博的开放性，遇到一系列安全挑战如垃圾内容，僵尸粉，微博攻击从未停止，除一般的安全策略，微博还在开放平台上使用多级安全审核策略以保护系统和用户。

#### 2.3 小结
    在程序设计与架构设计领域，模式变得越来越重要，正确使用模式可以预解决系统日后出现的一些问题，而模式的使用主要是明白使用场景，生搬硬套效果可能适得其反，适合自己应用场景，对模式“微创新”也是让人耳目一新的。

### 3.大型网站核心架构要素
    >>架构是最高层次的规划，例如人生蓝图，职业规划，是整体上的一个定性。
  
   一般来说，除了当前的系统功能需求外，软件架构还需考虑关注性能、可用性、伸缩性、扩展性和安全性这5个架构要素。架构设计过程中需要平衡这5个要素之间的关系以实现需求和架构目标，也可通过考察这些架构要素来衡量一个软件架构设计的优劣，判断其是否满足期望。
#### 3.1 性能 （主要是访问速度快）
    网站性能主要体现在网站响应速度上，响应差会严重影响用户体验，性能提升可以在浏览器访问服务器过程的各个环节下手处理。

    * 在浏览器端，可以通过浏览器缓存，使用页面压缩，合理布局页面，减少cookie传输等手段改善性能。
    * 可以使用_cdn_，将网站静态内容缓存到离用户近的网络服务商机房；可以在网站机房部署_反向代理服务器_，缓存热点文件，加快访问速度，减轻应用服务器负载压力。
    * 在应用服务器端，可使用服务器本地缓存和分布式缓存，通过_缓存_内的热点数据处理用户请求，加快请求处理过程，减轻数据库负载压力。
    * 通过异步操作将用户请求发送至_消息队列_等待后续任务处理，而当前请求直接返回响应给用户。
    * 在网站有很多用户高并发请求情况下，可将多台应用服务器组成集群共同对外服务，提升整体处理能力，改善性能。
    * 在_代码_层面，可通过使用多线程，改善内存管理等手段优化性能。
    * 在数据库_服务器端_，索引，缓存，sql优化等性能优化手段已经比较成熟。而方兴未艾nosql数据库在性能方面的优势也日趋明显。
    
    衡量网站性能有一系列指标，重要的有响应时间，tps,系统性能计数器等，通过测试这些指标以确定系统设计是否达到目标。这些指标也是网站监控的重要参数，监控这些指标可分析系统瓶颈，
预测网站容量，并对异常指标进行报警，保障系统可用性。网站需要长时间运行还必须保证在持续运行且访问压力不均匀的情况下保持稳定的性能特性。

#### 3.2 可用性 （保持高可用，不会被宕机影响）
    一些知名大型网站可用性可以做到4个9以上的可用性，也就是可用性超过_99.99%_；
    商用服务器硬件并不保证不_宕机_，所以高可用的前提是假设服务器每天都有一部分宕机，再此情况下保持高可用。

    网站高可用的主要手段是_冗余_，应用部署在多台服务器上同时提供访问，数据存储在多台服务器上互相备份，任何一台服务器宕机都不会影响应用整体使用，也不会导致数据丢失。

    对于_应用服务器_，多台应用服务器通过负载均衡设备组成一个集群共同对外提供服务，这样某一台服务器宕机只要把请求切换到其他服务器就可实现应用高可用，但是有一个前提是应用服务器上不能保存请求的会话信息，
否则服务器宕机，会话丢失，即使将用户请求转发到其他服务器上也无法完成业务办理。

    对于_存储服务器_，由于其上存储着数据，需要对数据即使备份，当存储服务器宕机将数据访问请求到其他存储服务器上，并进行数据恢复以保证继续有服务器宕机的时候数据仍可用。

    除了运行环境，网站的高可用还需要软件开发过程的质量保证，通过预发布验证，自动化测试，自动化发布灰度发布等手段，减少故障引入线上环境的可能。

    衡量一个系统架构设计是否满足高可用的目标，就是假设系统中任何一台或多台服务器宕机或者出现各种不可预期的问题时，系统整体依然保证可用。

#### 3.3 伸缩性
     大型网站需要面对大量用户的高并发访问和存储海量数据，所谓伸缩性是指不断向集群中加入服务器的手段来缓解不断上升的用户并发访问压力和不断增长的数据存储需求。

     衡量系统伸缩性主要标准是是否可以提供多台服务器构建集群，是否容易添加服务器，加入服务器是否可以提供和原来的服务器无差别的提供服务，集群中的服务器总量是否有限制。

     对于_应用服务器_，只要服务器上不保存数据，所有服务器都是对等的，通过使用合适的负载均衡设备就可向集群中不断加入服务器。
     
     对于_缓存服务器_，加入新服务器可能导致缓存路由失效，进而导致集群中大部分缓存数据无法访问，需要改进缓存路由算法保证缓存数据的可访问性。

     关系数据库虽支持数据复制，主从热备等机制，但很难做到大规模集群的可伸缩性，因此关系数据库的集群伸缩性方案必须在数据库之外实现。通过路由分区等手段将部署到多个数据库的服务器组成一个集群。

     至于nosql数据库产品，由于其天生是为海量数据而生，因此其对伸缩性的支持通常都非常好，可以做到在较少运维参与的情况下实现集群规模的线性伸缩。

#### 3.4 扩展性
     扩展性注重网站的功能需求，设计网站需要考虑设计网站的架构使其能够快速响应需求变化，使网站可扩展；
     主要评价标准是扩展产品，对现有产品尽量透明无影响，产品之间少耦合，实现新功能对旧有的产品和功能不受牵连影响。
     
     网站可伸缩性主要手段是事件驱动架构和分布式服务。
     
    事件驱动架构在网站中通过消息队列实现，将用户请求和其他业务事件构造成消息发布到消息队列，消息的处理者作为消费者从消息队列中获取消息进行处理，消息产生和消息处理分离开来，可以透明地增加消息生产者任务或新消息消费者任务，降低耦合度。
    
    分布式服务在扩展性方面主要是将业务和可复用的服务分离开，通过分布式服务框架调用可复用的基础服务。
    大型网站还通过提供服务（即api接口）吸引开发者，扩展自身网站业务和开发周边产品。     

#### 3.5 安全性
    保证网站对现在的和潜在的攻击和危险有自身很好的防御系统。

#### 3.6 小结
   **_性能，可用性，伸缩性，扩展性和安全性是网站架构的最核心的几个要素，这几个要素解决了大型网站架构设计的大部分挑战也克服了。
接下来第二章围绕着5个架构要素组织说明_**。



## 第二章 架构


### 4.瞬时响应 ：网站的高性能架构

#### 4.1 网站性能测试
#####  1. 不同人眼中看到的性能点是不一样的，用户看到的是鼠标点击到返回响应的效果；开发人员侧重系统吞吐，并发处理能力等性能，运维人员看到的是基础设施性能和资源利用率。
#####  2. 性能测试指标
    1. 响应时间 ， 指应用发起请求到最后响应数据的时间。直观反映了系统的“快慢”。测试过程中通常测试程序发起以万记的请求，再计算平均响应时间。
    
    2. 并发数 ， 指系统能同时处理的请求的数目，这个数字也反映了系统的负载特性，对于网站而言，并发数即并发用户数。
     在网站设计初期，产品和运营就需要规划不同发展阶段用户数，依次为基础，推算在线用户和在线并发用户，这些指标是系统非功能设计的重要依据。

    3. 吞吐量 ， 指单位时间系统能处理的请求数量，对于网站，可以用“请求数/秒”or “页面数/秒”等来衡量，常用衡量指标有TPS(美妙事物数),HPS(美妙http请求数），QPS(每秒查询数)等，

    4. 性能计数器 , 描述服务器或操作系统性能的重要数据指标，对其进行监控，入股超出阀值对运维和开发人员报警。
#####  3.性能测试方法
  * 性能测试    对系统加压力，测试是否能在资源可接受范围内，达到性能预期。
  * 负载测试    对系统施压，直到某项资源呈饱和状态，此时如果再加压，系统处理能力不增反降
  * 压力测试    测试系统奔溃临界状态，获得系统最大的压力承受能力。
  * 稳定性测试  在不同环境，时间，压力下，更好的模拟了生产环境，测试系统的稳定性
     所谓的增加压力，在系统测试环境下即增加测试程序的并发请求数。前三者压力测试压力不断增加，性能测试遵循抛物线规律，x轴为系统资源， y轴为吞吐量；系统的绝大部分使用场景在性能测试范围内；
#####  4. 性能优化策略
  1.性能分析
     排查网站性能瓶颈，检查请求处理各个环节的日志，分析那个环节响应时间不合理，超过预期；然后检查监控数据，排查分析影响性能的主要因素是内存，磁盘，网络，还是CPU，还是代码问题，架构设计问题。或是系统资源确实不足。
  2.性能优化
     定位具体问题后，需要进行性能优化，根据网站分层架构，分为web前端性能优化，应用服务器性能优化，存储服务器性能优化。



####  4.2 web前端性能优化
>> web前端指网站业务逻辑之前的部分，包括浏览器加载，网站视图模型，图片服务，CDN服务等。 主要优化手段有优化浏览器访问，使用反向代理,CDN等；

##### 4.2.1 浏览器访问优化
   1. 减少http请求 
     http请求是无状态的应用层协议，每次http请求都要建立通信链路，进行数据传输，而在服务器端，每个http请求都要创立独立的线程去处理，开销很昂贵，可减少http请求数目有效提升访问性能。
   2. 使用浏览器缓存
     一些静态资源图片，css,js可以缓存，通过设置http头的cache-control,expires属性，设定浏览器缓存，时间可以自定义。 有时候更新js文件，此时需要跟新文件名，生成一个新的js文件更新到HTML文件的引用中（解决缓存js的问题）。
     使用浏览器缓存策略的网站在更新静态资源时，应采用批量更新方法，挨个批量更新每个文件。防止用户浏览器大量缓存失效。
   3. 启用压缩
     启用压缩，对文本文件html,css,js压缩效率达80%以上，适当使用，会增大浏览器和服务器压力。
   4. css放页面最上面，js放最下面
     css在下载完全部css后才对整个页面渲染，js则是浏览器在加载js后立即执行，有时会造成页面卡死。     
   5. 减少cookie传输
     cookie会包含在每次请求和响应中。因此cookie不宜大，另外请求静态资源如css,js发送cookie没意义，可考虑将静态资源放到独立静态服务器上。

##### 4.2.2 CDN加速
     cdn部署在机房，相当于缓存，距离用户近，一般将静态资源，访问频率高的资源放到缓存服务器上。
     
##### 4.2.3 反向代理
     传统代理位于浏览器一侧，可发送浏览器的请求给网络服务器；代理服务器在服务端一侧，可接受用户http请求，分发给不同服务器；
     反向代理服务器可提供静态资源的缓存和一些常用热门动态资源的缓存，减轻服务器压力。
     此外，反向代理具有负载均衡的功能，通过负载均衡的应用集群可提升系统总体处理能力，提升系统并发情况下性能。
#### 4.3 应用服务器性能优化
   应用服务器是处理网站业务的服务器，网站的业务代码部署在这里，同样是网站最复杂，变化最多的地方，优化手段主要是缓存，集群，异步等。
##### 4.3.1 分布式缓存
  >网站性能优化第一定律，优先考虑使用缓存优化性能。

     回顾网站架构演化历程，网站遇到瓶颈第一想到的解决方案是用缓存，整个网站应用中，缓存无处不在，既存在于浏览器也存在应用服务器和数据库服务器，既可对数据缓存也可对文件缓存，对页面片段缓存。
   1. 缓存的基本原理
      缓存存储在访问速度较高的介质中，访问速度快，减少访问时间，另一方面缓存失计算过的数据，减少计算时间。 
      缓存的本质是一个内存hash表。网站应用中，数据缓存以一对key,value的形式存储在内存hash表中； hash表的数据读写时间复杂度为O(1);
      换存主要存放那些读写比很高，又很少变化的数据，如商品类目，组织机构，热门词搜索列表，热门商品信息等。 应用程序度读数据先从缓存读取，读取不到再去数据库读取并缓存到缓存中；
      网站数据访问遵循28定律，所以将20%的数据缓存起来，可很好的改善系统性能，提高读取速度，减低存储访问压力。

  2. 合理使用缓存
     由于缓存使用内存作为介质，内存资源很宝贵，所以频繁修改的数据，没有热点的访问都不应该作为缓存。
     一般会对缓存的数据设置失效时间，一旦超时，就需要重新加载数据库；因此缓存数据和实际被修改数据有一定的时间差，当然可以修改数据时立即更新缓存，不过这也会带来更多系统开销和事物一致性问题。
     缓存可用性：
     由于网站规模越来愈大，缓存数据量很大，而缓存一旦失效，要求数据能重新冲数据库里读取出来，此时如果数据库承受不住压力，就会宕机，称为缓存雪崩。
     分布式缓存服务器集群：
     通过分布式缓存服务器集群，将缓存数据分布到集群多台服务器上可在一定程度上改善缓存的可用性。若一台缓存服务器宕机，只有部分缓存数据丢失，再去数据库获取，数据库可以承受这个压力。

**产品**
>>产品设计之初就有一个明确定位，实现什么功能，什么是产品不提供的特性。 产品在漫长的生命周期可能会遇到形形色色的诱惑和各种困难左右产品的方向， 什么都想做的产品，最后有可能成为一个失去生命力的四不像；

     缓存预热：
     缓存存放的是热点数据，使用LRU(最近最久未使用算法)，新启动的缓存没有数据，在重建缓存数据过程中是系统的性能和数据库负载都不太好，因此在缓存系统启动时就可以吧热点数据加载好，这个手段叫做缓存预热；对于一些元数据可在启动时加载数据库中的数据到缓存预热；
     缓存穿透：
     如果遇到恶意攻击，持续访问冷数据，这样所有请求都落到数据库服务上，容易对数据库造成压力甚至崩溃，一个简单的对策是将不存在的数据也缓存起来（value=null）;
  3.分布式缓存架构
     分布式缓存失指缓存部署在多个服务器组成的集群中。以集群的方式提供缓存服务，其架构方式有2种，一种是以jboss cache为代表的需要同步更新的分布式缓存，另一种是以memcached为代表的不互相通信的分布式缓存。
     
     jboss cache在分布式缓存服务器上保持缓存同步，某台服务器更新时，其他服务器保持update，delete；通常将缓存和应用程序部署在同一台服务器上，因此其限制性也是很明显的，首先缓存数据受限于单一服务器内存空间，其次集群规模较大时，缓存更新时要通知所有服务器，代价很大；
     因此jboss cache这种方案更多见于企业应用系统中，而很少在大型网站使用。

     大型网站需要缓存数据量比较大，可能需要TB级别的内存做缓存，需要另一种分布式缓存，Memcached采用一种集中式的缓存集群管理，也被称作互不通信的分布式架构方式。缓存与应用分离部署，缓存系统部署在一组专门的服务器上，应用程序通过一致性hash等路由算法选择缓存服务器远程访问缓存数据，
     缓存之间不相互通信，缓存集群的规模可以很容易实现扩容，具有良好的可伸缩性。
  4. Memcached
     memcached曾一度是网站分布式缓存的代名词，被大量网站使用，其简单的设计、优异的性能，互不通信的服务器集群，海量数据可伸缩的架构令架构师们趋之若鹜。
     
     虽然今年来许多NoSql产品层出不穷，在数据持久化、支持复杂数据机构，甚至性能方面有许多产品由于memcached，但memcached由于其简单，稳定，专注的特点，仍在分布式缓存领域占据重要地位。

    1. 简单的通信协议，通信协议有tcp,udp,http协议，通信序列化协议有xml,json等来传数据，使通信的两方能互相识别。memcached使用tcp协议通信，其序列化协议是自定义的文本协议，非常简单。
    2. 丰富的客户端程序，memcached的通信协议非常简单，能支持该协议的客户端都可以和memcached服务器通信，几乎支持所有主流的网站编程语言，如java,c/c++,perl,php,python,ruby等。
    3. 高性能的网络通信，memcached服务端通信模块基于libevent,一个支持事件触发的网络通信程序库，libevent在稳定的长连接方面的表现正式memcached所需要的。
    4. 高效的内存管理，最小内存块是chunk，固定大小，然后一组chunk组成slab,一组slab组成slab_class, 采用LRU算法释放最近最久未被访问的内存； *这种方式会带来内存浪费问题，如果启动参数配置不合理，浪费会更加惊人！使用需注意。*
    5. 互不通信的服务器集群架构，正是这个特性使memcached从Jboss cache, oscache等众多分布式缓存产品脱颖而出，满足网站对海量缓存数据的需求，而其客户端路由算法一致性hash更成为数据存储伸缩性架构设计的经典模式（第6章）。
   实际也正是集群内服务器互不通信使得集群可以做到几乎无限制的线性伸缩，这也是目前流行的许多大数据技术的基本架构特点。

##### 4.3.2 异步操作
 > 使用消息队列将调用异步化，可改善网站的扩展性，事实上，使用消息队列还可以提升网站系统的性能。
 >> 消息队列服务器，未使用时：1.客户端发起请求-->网站应用服务器-->数据库服务器
                    使用时：  2.客户端发起请求-->网站应用服务器-->消息队列服务器-->数据库服务器

     在不使用消息队列时，客户端请求数据直接写入数据库，在高并发情况下会对数据库造成很大压力，同事响应延迟加剧。在使用消息队列后，用户请求的数据发送给消息队列后立即返回，再由消费队列的消费者进程（通常情况下，该进程通常独立部署在专门的服务器集群上）从队列中获取数据，异步写入数据库。由于消息队列服务器处理速度远快于数据库（消息队列服务器比数据库具有更好的伸缩性），因此用户的响应延迟也可得到有效改善。
     消息队列有很好的流量削峰作用。通过异步处理，将短时间高并发产生的事务消息存储在消息队列中，从而削平高峰期的并发事务。
     需要注意的是，由于数据写入消息队列后立即返回给用户，数据在后续的业务校验，写数据库操作可能失败，因此在使用消息队列进行业务异步处理后，需要适当修改业务流程进行配合，如订单提交后，
    订单数据写入消息队列，不能立即返回用户订单提交成功，需要在消息队列的订单消费者进程真正处理完该订单，甚至商品出库后，再通知电子邮件或sms消息通知用户订单成功，以免交易纠纷。

##### 4.3.3 使用集群
     在网站高并发访问的场景下，使用负载均衡技术为一个应用构建一个由多台服务器组成的服务器集群，将并发访问请求分发到多台服务器上，减轻单一服务器压力，提高响应速度。
     负载均衡过程； 用户浏览器-->负载均衡服务器-->web服务器集群

##### 4.3.4 代码优化
     网站的业务逻辑实现代码主要部署在应用服务器上，需要处理复杂的并发事务。下面主要关注几个优化方面：
      1. 多线程
       多用户访问时网站的基本需求，大型网站的并发用户数会达到数万，单太服务器的并发用户也会达到数百。CGI编程时代，每个用户请求都会创建一个独立的系统进程去处理。由于线程比进程更轻量，更少战友系统资源，切换代价更小，所以目前主要的web应用服务器都采用多线程的方式响应并发用户请求，因此网站开发天然就是多线程编程。
      从资源利用的角度看:  使用多线程主要是为了更好的利用多核cpu,当前线程进行io处理，会被阻塞释放cpu以等待io操作完成，io(不管是磁盘id还是网络id)通常需要较长时间。cpu可以调度其他线程进行处理。
        线程启动数：   启动线程数=[任务执行时间/(任务执行时间-IO等待时间)]*CPU内核数。
            最佳启动线程数和CPU内核数量成正比，和IO阻塞时间成反比。如果任务都是cpu计算型任务，那么线程数量最多不超过cpu内核数。因为启动再多线程，CPU也来不及调度；相反如果是任务需要等待磁盘操作， 网络响应，那么多启动线程有助于提高任务并发度，提高系统吞吐能力，改善系统性能。
        线程安全问题：  多线程使用另外一个问题是线程安全问题，即多线程并发对某个资源进行修改，导致数据混乱。这也是缺乏经验的网络工程师最容易犯错的地方。线程安全bug难以测试和重现，网站故障中许多“灵异事件”都和多线程并发问题有关。对网站而言，每一行代码都会被多线程执行，因为用户的请求是并发提交的，所有的资源----对象，内存，文件，数据库，乃至另一个线程都可能被多线程并发访问。
       
        编程中，解决线程安全的主要手段有以下几点。
        * 将对象设计成无状态对象，java中servlet就是无状态对象
        * 使用局部对象， 即在方法内部创建对象，这样对象会被每个进入方法的线程创建。除非线程有意识地将这些对象传递给其他线程，否则不会出现对象被多线程并发访问的清形。
        * 并发访问资源时使用锁， 即多线程访问资源时，对资源加锁，使多线程并发操作转化为顺序操作，避免资源被并发修改。
     2. 资源复用
        系统运行时，要尽量减少那些开销很大的系统资源的创建和销毁，如数据库连接、网络通信连接、线程、复杂对象等，资源复用主要有两种模式：单例singleton和对象池object pool。 
        目前web开发中主要使用贫血模式，从service到dao都是些无状态对象，无需重复创建，使用单例模式就自然而然了，事实上，java开发常用的对象容器spring默认构造的对象都是单例的，spring的单例是spring容器管理的单例，而不是单例模式构造的单例。
        对象池模式通过复用对象实例，减少对象创建和资源消耗。实际使用中，数据库连接基本使用连接池（connection pool）方式。数据库连接对象创建好以后，将连接对象放入对象连接池中，应用程序要连接时，就从对象池中获取一个空闲的连接使用，使用完毕再将该对象归还到对象池中即可，不需要创建新的连接。
        前面说过，对于每个webhttp请求，web应用服务器都需要创建一个独立的线程去处理，这方面，应用服务器也采用线程池的方式。 本质上连接池，线程池都是对象池。池管理方式基本相同。
     3. 数据机构
        求hashcode过程中，相似字符串hashcode可能比较相近，在某些应用场景是不符合规范的，此时可以对原本的字符串取信息指纹，再对指纹求hashCode,
     4. 垃圾回收
        如果web应用运行在jvm等具有垃圾回收功能发的环境中，那么垃圾回收可能对系统性能有巨大影响，理解垃圾回收机制有助于程序优化和参数调优，以及编写安全的代码。
        java JVM应该根据系统业务特点和对象生命周期，合理设置young generation和old generation大小，尽量减少full GC,事实上，某些web应用在整个运行期间可以做到从来不进行full GC。

#### 4.4  存储性能优化      
