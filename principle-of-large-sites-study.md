# 大型网站技术架构核心原理与案例分析  
> --阿里“教授” 李智慧
principle of large sites

* [高可用网站的质量保证](# 5.6 高可用网站的质量保证)

*精彩摘要*
> *高手定律 救世主定律*
>> 高手是在遇到问题不断解决顶着压力提升，遇到问题多了就成了高手，业务环境造就高手，例如在海量数据处理的场景可以成长出数据处理的高手。

>> 救世主定律，遇到问题，分析问题，解决问题。如果遇到问题匆匆从外面挖一个高手过来，指望高手可以如探囊取物轻松搞定，最后怕是只有彼此抱怨和伤害。许多问题只是看起来一样，具体问题具体对待，没有救世主。即没有救世主定律



###  1. 大型网站架构演化
#### 1.2大型网站架构演化发展历程

 >> *本书1.2部分架构的图例很清晰重要*
 
    1. _初始阶段_，  一台服务器，应用程序，文件，数据库都在一起；一个基于所有开源软件的小网站建立；
     2. _用户增加_， 应用服务和数据服务分离  应用程序在一台服务器，需要处理复杂的业务逻辑，所以需要CPU又快又强大； 数据库在一台服务器，需要快速磁盘检索和数据缓存，因此需要更快的硬盘和更大的内存； 文件服务器在另一台服务器，需要存放上传的文件，需要更大的硬盘。
    3. _使用缓存改善网站性能_，  由于用户增多，数据库压力太大导致延迟访问，由此：数据访问遵循2/8法则，所以想到使用缓存。 缓存分2种，一种应用服务器本地缓存，这种受服务器内存限制，且会与应用服务器争内存；另一种是使用远程分布式集群缓存，部署大内存服务器作为缓存服务器，可以在理论上做到不受内存容量限制的缓存服务；
    4. _使用应用服务器集群改善网站的并发处理能力_，使用集群是网站解决高并发、海量数据问题的常用手段。 用户过于庞大，不要一味加大服务器内存，性能；应用服务器实现集群是网站可伸缩集群架构设计中较为简 单成熟的一种。
    此时通过负载均衡调度服务器，可将来自用户浏览器的访问请求分发到应用服务器集群中任何一台服务器上，压力增大的话在集群中加入更多服务器即可，使应用服务器的负载压力不再成为整个网站的瓶颈。
    5. _数据库读写分离_，  网站使用缓存后，绝大部分数据库操作访问都可以不通过数据库就能完成，但仍有一些写操作或缓存过期，缓存不命中的操作需要访问数据库。用户增大时，数据库又成为网站服务支持的瓶颈。
    大部分数据库提供主从热备功能，因此配置主从数据库关系，可以将一台数据库服务器数据更新到另一台服务器上，利用这个数据库特性实现读写分离。此时，通常在应用服务器端使用专门的数据访问模块，读写数据。
    6. _使用反向代理和cdn加速网站响应_
    国内复杂的网络环境，不同地区用户访问网站速度差别很大。加入网站响应主要有反向代理和CDN加速；2者都是经过负载均衡调度服务器请求的，CDN和反向代理基本原理都是缓存，cdn是从部署在网络提供商的机房服务器取缓存，反向代理从反向代理的服务器取真实应用服务器的缓存。
     使用CDN和反向代理目的都是尽早返回数据给用户，取缓存服务器的数据，一方面加快用户访问速度，另一方面减轻后端服务器的负载压力；
    7. _使用分布式文件系统和分布式数据库系统_。
     任何单一的服务器都满足不了大型网站持续增长的业务需求，数据库读写分离是拆分了2台服务器，随着数据增长，最终需要分布式数据库和分布式文件系统服务器。
    _分布式数据库是网站数据拆分的最后手段_，只有单表数据规模非常庞大才使用，不到不得已，网站更常用数据库拆分手段是业务分库，将不同业务的数据库部署在不同的物理服务器上。
    8. _使用noSql和搜索引擎_
    随着网站业务复杂化，对数据存储和检索需求也越来越复杂，网站需要采用一些非关系型数据库技术如NoSql和非数据库查询技术如搜索引擎。
    者2者都是源自互联网技术手段，对可伸缩的分布式特性具有更好的支持，应用服务器则通过一个统一的数据访问模块访问各种数据，减轻应用程序管理诸多数据源的麻烦。
    9. _业务拆分_    
    大型购物交易网站，会拆分各个业务模块，如商铺，订单，卖家，买家。分归不同的业务团队负责。
    10. _分布式服务_
     通过分布式服务调用共用业务服务（可复用业务连接数据库），来完成具体的业务操作。云计算平台已经作为一种基础资源出售，中小企业不用注重实现细节，直接租用服务即可。

###  2. 大型网站架构模式
_*大型网站架构思路：拆分，从横向纵向拆分，从逻辑上物理上拆分，拆分的粒度很细，在物理上实现微服务集群，远程协同调用工作，降低访问压力*_

>   我们通过学习掌握大型网站架构的一般思路和解决方案，以指导我们的架构设计 

>   为解决大型网站面临的高并发访问，海量数据处理，高可靠运行这些挑战，大型互联网公司提出许多解决方案以实现高性能，高可用，易伸缩可扩展安全等架构目标；

#### 2.1 网站架构模式
   1. 分层  *横向分思想* 各模块分层，例如视图层，业务层，持久层，各模块拆分，人员负责维护自己的模块，保证接口稳定即可；
       分层首先是用在规划软件清晰的逻辑结构便于开发，后来可以将不同层部署到不同服务器上，分层结构对网站支持高并发分布式方向发展至关重要，网站从小就应该分层。
    2. 分割  *纵向分思想*  网站越大，越需要纵向分割，比如在业务层分割，将粒度分割的很细，如购物，论坛，搜索，广告各模块，购物业务比较重还可以细分，如分割机票酒店业务，3C业务，小商品等等细的模块。
       这些模块不管是在逻辑上还是物理部署上，都是独立的。
    3. 分布式  分布式有自身的一些缺陷，如数据一致性，事物等的处理。
   * 常用分布式方案：分布式应用和服务（不同应用复用共同的服务，便于业务功能扩展）；
   * 分布式静态资源（动静分离）；
   * 分布式数据和存储（数据量p级别，一般分布存储，noSql产品一般也是分布式）； 
   * 分布式计算（业务的计算规模很庞大，如数据仓库数据分析统计，网站普遍使用Hadoop及其mapReduce分布式计算框架进行大数据量批处理计算（特点是移动计算而非移动数据，将计算程序分到数据所在位置以加速计算和分布式计算））
   * 此外，还有支持网站线上服务器配置实时更新的分布式配置，分布式环境下实现并发和协同的分布式锁；支持云存储的分布式文件系统等。
  4. 集群 
     集群是针对一部分用户集中访问的内容，做的相同应用的集群化部署，通过负载均衡设备对外提供服务。 集群提高系统的可用性，一方面提供备份，一方面解决并发压力。
  5. 缓存
     缓存就是将数据放在距离计算最近的位置以加快处理速度。
    * cdn 内容分发网络，部署在距离最近的运营商服务器，将一些常用的较少改变的数据缓存。 
    * 反向代理 反向代理，用户请求到达网络数据中心时，最先访问的是反向代理服务器，这里缓存了静态资源，不需要请求中心服务器就可返回数据给用户。
    * 本地缓存 应用服务器本地（内存）缓存热点数据，直接返回数据给请求。
    * 分布式缓存  大型网站缓存数据量大，缓存数据放到分布式集群。
  6. 异步
   * 系统解耦的一个重要手段是异步，单一服务器内部可通过多线程共享内存队列的方式实现异步，处在业务操作前面的线程将输出写入队列，后面的线程从队列读取数据进行处理。
   * 在分布式系统中，多个服务器通过分布式消息队列实现异步，分布式消息队列可看做是内存队列的分布式部署。
   * 异步队列是典型的生产者消费者模式。两者不存在直接调用，只要保持数据结构不变，彼此功能实现可以随意变化而不相互影响。
   * 异步消息队列有如下特性。
   1. 特高系统可用性，消费者宕机，生产者不影响工作；
   2. 加快网站响应速度 处在业务前端的生产者服务器处理完业务请求后，数据写入消息队列，不需要等消费者服务器处理即可返回，响应延迟减少
   3. 消除并发访问高峰 大流量访问时，使用消息队列，请求数据放入队列中，等待消费者服务器依次处理，不会对整个网站造成太大压力。
   4. 使用异步需注意场景，！
  7. 冗余 
     冗余及备份，对服务器备份形成集群，对数据定时备份，对数据库进行主从分离，实时同步热备份。 重要内容全球灾备数据中心。
  8. 自动化
     无人值守状况下网站可正常运行，目前大公司的自动化一般有 发布过程自动化，自动化代码管理，自动化测试，自动化安全监测，部署，自动化报警，失效回复等等。
     自动化贯穿整个网站开发以及运维过程。
  9. 安全
    * 例如 通过密码手机校验码进行身份验证，登录。 对登录，交易信息加密。网站使用验证码识别机器人防止滥用资源，对xss，sql注入等黑客攻击，进行编码转换等手段，对垃圾信息过滤，对交易等重要数据操作进行风险控制。

#### 2.2 架构模式在新浪微博的应用（_举例说微博具体怎么使用架构模式 完美_）
   _*新浪分三层部署*_

  1. 新浪微博从小网站lamp linux apache mysql php发展起来，现在系统分为三层，最下层是基础服务层，提供数据库，缓存，存储搜索等数据服务，以及其他一些
  基础的技术服务，这些服务支撑了新浪微博的海量数据和高并发访问，是整个系统的技术基础。
  2. 中间层是平台服务和应用服务层，新浪微博的核心是微博，关系和用户，他们被拆成独立的服务模块，通过依赖调用和共享基础数据构成了新浪微博的业务基础。
  3. 最上层是API和新浪微博业务层，由客户端和第三方应用通过调用api集成到新浪微博系统，共同组成一个生态系统。

  4. 这些被分层和分割后的业务模块和基础技术模块分布式部署，每个模块部署到一个独立的服务器集群上，通过远程调用方式相互依赖，新浪早期使用过MPSS技术，将
  多个应用部署到一台服务器，改变端口实现资源最大化利用，现在常用的方式是将物理机虚拟成多个虚拟机，再在虚拟机上部署应用，这样可以不改变端口部署应用。
  5. 新浪早期技术机构中，微博发布采用同步推模式，用户发布微博会立即将内容推送到关注人的推送列表中，这样明星用户发起微博会导致系统压力很大，延迟很慢；    后来改为异步推拉结合的方式，用户发表微博后系统将微博写入消息队列后立即返回，用户响应迅速，
  消息队列消费者任务将微博推送给当前在线的粉丝订阅列表中，非在线用户登陆后再根据关注列表拉去微博列表。
 
    由于微博刷新频繁，新浪微博使用多级缓存策略，热门微博和明星用户微博缓存在所有服务器上，在线用户的近期微博_缓存_在分布式缓存集群中，常见的刷微博操作，几乎全是缓存访问操作，可获得很好的系统性能。
    
    为提高系统整体可用性和性能，新浪微博启用了_多个数据中心_，这些数据中心既是地区用户访问中心，方便用户就近访问提高访问速度，也是数据冗余复制的灾备中心，所有用户和微博数通过远程消息系统在不同的数据中心之间_同步_，提升系统可用性。
    
    同时，新浪微博开发了一系列_自动化工具_，包括自动化监控，自动挂发布，自动化故障修复等。这些自动化工具可改善运维水平提高系统可用性。
 
    在_安全性_上，由于微博的开放性，遇到一系列安全挑战如垃圾内容，僵尸粉，微博攻击从未停止，除一般的安全策略，微博还在开放平台上使用多级安全审核策略以保护系统和用户。

#### 2.3 小结
    在程序设计与架构设计领域，模式变得越来越重要，正确使用模式可以预解决系统日后出现的一些问题，而模式的使用主要是明白使用场景，生搬硬套效果可能适得其反，适合自己应用场景，对模式“微创新”也是让人耳目一新的。

### 3.大型网站核心架构要素
    >>架构是最高层次的规划，例如人生蓝图，职业规划，是整体上的一个定性。
  
   一般来说，除了当前的系统功能需求外，软件架构还需考虑关注性能、可用性、伸缩性、扩展性和安全性这5个架构要素。架构设计过程中需要平衡这5个要素之间的关系以实现需求和架构目标，也可通过考察这些架构要素来衡量一个软件架构设计的优劣，判断其是否满足期望。
#### 3.1 性能 （主要是访问速度快）
    网站性能主要体现在网站响应速度上，响应差会严重影响用户体验，性能提升可以在浏览器访问服务器过程的各个环节下手处理。

    * 在浏览器端，可以通过浏览器缓存，使用页面压缩，合理布局页面，减少cookie传输等手段改善性能。
    * 可以使用_cdn_，将网站静态内容缓存到离用户近的网络服务商机房；可以在网站机房部署_反向代理服务器_，缓存热点文件，加快访问速度，减轻应用服务器负载压力。
    * 在应用服务器端，可使用服务器本地缓存和分布式缓存，通过_缓存_内的热点数据处理用户请求，加快请求处理过程，减轻数据库负载压力。
    * 通过异步操作将用户请求发送至_消息队列_等待后续任务处理，而当前请求直接返回响应给用户。
    * 在网站有很多用户高并发请求情况下，可将多台应用服务器组成集群共同对外服务，提升整体处理能力，改善性能。
    * 在_代码_层面，可通过使用多线程，改善内存管理等手段优化性能。
    * 在数据库_服务器端_，索引，缓存，sql优化等性能优化手段已经比较成熟。而方兴未艾nosql数据库在性能方面的优势也日趋明显。
    
    衡量网站性能有一系列指标，重要的有响应时间，tps,系统性能计数器等，通过测试这些指标以确定系统设计是否达到目标。这些指标也是网站监控的重要参数，监控这些指标可分析系统瓶颈，
预测网站容量，并对异常指标进行报警，保障系统可用性。网站需要长时间运行还必须保证在持续运行且访问压力不均匀的情况下保持稳定的性能特性。

#### 3.2 可用性 （保持高可用，不会被宕机影响）
    一些知名大型网站可用性可以做到4个9以上的可用性，也就是可用性超过_99.99%_；
    商用服务器硬件并不保证不_宕机_，所以高可用的前提是假设服务器每天都有一部分宕机，再此情况下保持高可用。

    网站高可用的主要手段是_冗余_，应用部署在多台服务器上同时提供访问，数据存储在多台服务器上互相备份，任何一台服务器宕机都不会影响应用整体使用，也不会导致数据丢失。

    对于_应用服务器_，多台应用服务器通过负载均衡设备组成一个集群共同对外提供服务，这样某一台服务器宕机只要把请求切换到其他服务器就可实现应用高可用，但是有一个前提是应用服务器上不能保存请求的会话信息，
否则服务器宕机，会话丢失，即使将用户请求转发到其他服务器上也无法完成业务办理。

    对于_存储服务器_，由于其上存储着数据，需要对数据即使备份，当存储服务器宕机将数据访问请求到其他存储服务器上，并进行数据恢复以保证继续有服务器宕机的时候数据仍可用。

    除了运行环境，网站的高可用还需要软件开发过程的质量保证，通过预发布验证，自动化测试，自动化发布灰度发布等手段，减少故障引入线上环境的可能。

    衡量一个系统架构设计是否满足高可用的目标，就是假设系统中任何一台或多台服务器宕机或者出现各种不可预期的问题时，系统整体依然保证可用。

#### 3.3 伸缩性
     大型网站需要面对大量用户的高并发访问和存储海量数据，所谓伸缩性是指不断向集群中加入服务器的手段来缓解不断上升的用户并发访问压力和不断增长的数据存储需求。

     衡量系统伸缩性主要标准是是否可以提供多台服务器构建集群，是否容易添加服务器，加入服务器是否可以提供和原来的服务器无差别的提供服务，集群中的服务器总量是否有限制。

     对于_应用服务器_，只要服务器上不保存数据，所有服务器都是对等的，通过使用合适的负载均衡设备就可向集群中不断加入服务器。
     
     对于_缓存服务器_，加入新服务器可能导致缓存路由失效，进而导致集群中大部分缓存数据无法访问，需要改进缓存路由算法保证缓存数据的可访问性。

     关系数据库虽支持数据复制，主从热备等机制，但很难做到大规模集群的可伸缩性，因此关系数据库的集群伸缩性方案必须在数据库之外实现。通过路由分区等手段将部署到多个数据库的服务器组成一个集群。

     至于nosql数据库产品，由于其天生是为海量数据而生，因此其对伸缩性的支持通常都非常好，可以做到在较少运维参与的情况下实现集群规模的线性伸缩。

#### 3.4 扩展性
     扩展性注重网站的功能需求，设计网站需要考虑设计网站的架构使其能够快速响应需求变化，使网站可扩展；
     主要评价标准是扩展产品，对现有产品尽量透明无影响，产品之间少耦合，实现新功能对旧有的产品和功能不受牵连影响。
     
     网站可伸缩性主要手段是事件驱动架构和分布式服务。
     
    事件驱动架构在网站中通过消息队列实现，将用户请求和其他业务事件构造成消息发布到消息队列，消息的处理者作为消费者从消息队列中获取消息进行处理，消息产生和消息处理分离开来，可以透明地增加消息生产者任务或新消息消费者任务，降低耦合度。
    
    分布式服务在扩展性方面主要是将业务和可复用的服务分离开，通过分布式服务框架调用可复用的基础服务。
    大型网站还通过提供服务（即api接口）吸引开发者，扩展自身网站业务和开发周边产品。     

#### 3.5 安全性
    保证网站对现在的和潜在的攻击和危险有自身很好的防御系统。

#### 3.6 小结
   **_性能，可用性，伸缩性，扩展性和安全性是网站架构的最核心的几个要素，这几个要素解决了大型网站架构设计的大部分挑战也克服了。
接下来第二章围绕着5个架构要素组织说明_**。



## 第二章 架构


### 4.瞬时响应 ：网站的高性能架构

#### 4.1 网站性能测试
#####  1. 不同人眼中看到的性能点是不一样的，用户看到的是鼠标点击到返回响应的效果；开发人员侧重系统吞吐，并发处理能力等性能，运维人员看到的是基础设施性能和资源利用率。
#####  2. 性能测试指标
    1. 响应时间 ， 指应用发起请求到最后响应数据的时间。直观反映了系统的“快慢”。测试过程中通常测试程序发起以万记的请求，再计算平均响应时间。
    
    2. 并发数 ， 指系统能同时处理的请求的数目，这个数字也反映了系统的负载特性，对于网站而言，并发数即并发用户数。
     在网站设计初期，产品和运营就需要规划不同发展阶段用户数，依次为基础，推算在线用户和在线并发用户，这些指标是系统非功能设计的重要依据。

    3. 吞吐量 ， 指单位时间系统能处理的请求数量，对于网站，可以用“请求数/秒”or “页面数/秒”等来衡量，常用衡量指标有TPS(美妙事物数),HPS(美妙http请求数），QPS(每秒查询数)等，

    4. 性能计数器 , 描述服务器或操作系统性能的重要数据指标，对其进行监控，入股超出阀值对运维和开发人员报警。
#####  3.性能测试方法
  * 性能测试    对系统加压力，测试是否能在资源可接受范围内，达到性能预期。
  * 负载测试    对系统施压，直到某项资源呈饱和状态，此时如果再加压，系统处理能力不增反降
  * 压力测试    测试系统奔溃临界状态，获得系统最大的压力承受能力。
  * 稳定性测试  在不同环境，时间，压力下，更好的模拟了生产环境，测试系统的稳定性
     所谓的增加压力，在系统测试环境下即增加测试程序的并发请求数。前三者压力测试压力不断增加，性能测试遵循抛物线规律，x轴为系统资源， y轴为吞吐量；系统的绝大部分使用场景在性能测试范围内；
#####  4. 性能优化策略
  1.性能分析
     排查网站性能瓶颈，检查请求处理各个环节的日志，分析那个环节响应时间不合理，超过预期；然后检查监控数据，排查分析影响性能的主要因素是内存，磁盘，网络，还是CPU，还是代码问题，架构设计问题。或是系统资源确实不足。
  2.性能优化
     定位具体问题后，需要进行性能优化，根据网站分层架构，分为web前端性能优化，应用服务器性能优化，存储服务器性能优化。



####  4.2 web前端性能优化
>> web前端指网站业务逻辑之前的部分，包括浏览器加载，网站视图模型，图片服务，CDN服务等。 主要优化手段有优化浏览器访问，使用反向代理,CDN等；

##### 4.2.1 浏览器访问优化
   1. 减少http请求 
     http请求是无状态的应用层协议，每次http请求都要建立通信链路，进行数据传输，而在服务器端，每个http请求都要创立独立的线程去处理，开销很昂贵，可减少http请求数目有效提升访问性能。
   2. 使用浏览器缓存
     一些静态资源图片，css,js可以缓存，通过设置http头的cache-control,expires属性，设定浏览器缓存，时间可以自定义。 有时候更新js文件，此时需要跟新文件名，生成一个新的js文件更新到HTML文件的引用中（解决缓存js的问题）。
     使用浏览器缓存策略的网站在更新静态资源时，应采用批量更新方法，挨个批量更新每个文件。防止用户浏览器大量缓存失效。
   3. 启用压缩
     启用压缩，对文本文件html,css,js压缩效率达80%以上，适当使用，会增大浏览器和服务器压力。
   4. css放页面最上面，js放最下面
     css在下载完全部css后才对整个页面渲染，js则是浏览器在加载js后立即执行，有时会造成页面卡死。     
   5. 减少cookie传输
     cookie会包含在每次请求和响应中。因此cookie不宜大，另外请求静态资源如css,js发送cookie没意义，可考虑将静态资源放到独立静态服务器上。

##### 4.2.2 CDN加速
     cdn部署在机房，相当于缓存，距离用户近，一般将静态资源，访问频率高的资源放到缓存服务器上。
     
##### 4.2.3 反向代理
     传统代理位于浏览器一侧，可发送浏览器的请求给网络服务器；代理服务器在服务端一侧，可接受用户http请求，分发给不同服务器；
     反向代理服务器可提供静态资源的缓存和一些常用热门动态资源的缓存，减轻服务器压力。
     此外，反向代理具有负载均衡的功能，通过负载均衡的应用集群可提升系统总体处理能力，提升系统并发情况下性能。
#### 4.3 应用服务器性能优化
   应用服务器是处理网站业务的服务器，网站的业务代码部署在这里，同样是网站最复杂，变化最多的地方，优化手段主要是缓存，集群，异步等。
##### 4.3.1 分布式缓存
  >网站性能优化第一定律，优先考虑使用缓存优化性能。

     回顾网站架构演化历程，网站遇到瓶颈第一想到的解决方案是用缓存，整个网站应用中，缓存无处不在，既存在于浏览器也存在应用服务器和数据库服务器，既可对数据缓存也可对文件缓存，对页面片段缓存。
   1. 缓存的基本原理
      缓存存储在访问速度较高的介质中，访问速度快，减少访问时间，另一方面缓存失计算过的数据，减少计算时间。 
      缓存的本质是一个内存hash表。网站应用中，数据缓存以一对key,value的形式存储在内存hash表中； hash表的数据读写时间复杂度为O(1);
      换存主要存放那些读写比很高，又很少变化的数据，如商品类目，组织机构，热门词搜索列表，热门商品信息等。 应用程序度读数据先从缓存读取，读取不到再去数据库读取并缓存到缓存中；
      网站数据访问遵循28定律，所以将20%的数据缓存起来，可很好的改善系统性能，提高读取速度，减低存储访问压力。

  2. 合理使用缓存
     由于缓存使用内存作为介质，内存资源很宝贵，所以频繁修改的数据，没有热点的访问都不应该作为缓存。
     一般会对缓存的数据设置失效时间，一旦超时，就需要重新加载数据库；因此缓存数据和实际被修改数据有一定的时间差，当然可以修改数据时立即更新缓存，不过这也会带来更多系统开销和事物一致性问题。
     缓存可用性：
     由于网站规模越来愈大，缓存数据量很大，而缓存一旦失效，要求数据能重新冲数据库里读取出来，此时如果数据库承受不住压力，就会宕机，称为缓存雪崩。
     分布式缓存服务器集群：
     通过分布式缓存服务器集群，将缓存数据分布到集群多台服务器上可在一定程度上改善缓存的可用性。若一台缓存服务器宕机，只有部分缓存数据丢失，再去数据库获取，数据库可以承受这个压力。

**产品**
>>产品设计之初就有一个明确定位，实现什么功能，什么是产品不提供的特性。 产品在漫长的生命周期可能会遇到形形色色的诱惑和各种困难左右产品的方向， 什么都想做的产品，最后有可能成为一个失去生命力的四不像；

     缓存预热：
     缓存存放的是热点数据，使用LRU(最近最久未使用算法)，新启动的缓存没有数据，在重建缓存数据过程中是系统的性能和数据库负载都不太好，因此在缓存系统启动时就可以吧热点数据加载好，这个手段叫做缓存预热；对于一些元数据可在启动时加载数据库中的数据到缓存预热；
     缓存穿透：
     如果遇到恶意攻击，持续访问冷数据，这样所有请求都落到数据库服务上，容易对数据库造成压力甚至崩溃，一个简单的对策是将不存在的数据也缓存起来（value=null）;
  3.分布式缓存架构
     分布式缓存失指缓存部署在多个服务器组成的集群中。以集群的方式提供缓存服务，其架构方式有2种，一种是以jboss cache为代表的需要同步更新的分布式缓存，另一种是以memcached为代表的不互相通信的分布式缓存。
     
     jboss cache在分布式缓存服务器上保持缓存同步，某台服务器更新时，其他服务器保持update，delete；通常将缓存和应用程序部署在同一台服务器上，因此其限制性也是很明显的，首先缓存数据受限于单一服务器内存空间，其次集群规模较大时，缓存更新时要通知所有服务器，代价很大；
     因此jboss cache这种方案更多见于企业应用系统中，而很少在大型网站使用。

     大型网站需要缓存数据量比较大，可能需要TB级别的内存做缓存，需要另一种分布式缓存，Memcached采用一种集中式的缓存集群管理，也被称作互不通信的分布式架构方式。缓存与应用分离部署，缓存系统部署在一组专门的服务器上，应用程序通过一致性hash等路由算法选择缓存服务器远程访问缓存数据，
     缓存之间不相互通信，缓存集群的规模可以很容易实现扩容，具有良好的可伸缩性。
  4. Memcached
     memcached曾一度是网站分布式缓存的代名词，被大量网站使用，其简单的设计、优异的性能，互不通信的服务器集群，海量数据可伸缩的架构令架构师们趋之若鹜。
     
     虽然今年来许多NoSql产品层出不穷，在数据持久化、支持复杂数据机构，甚至性能方面有许多产品由于memcached，但memcached由于其简单，稳定，专注的特点，仍在分布式缓存领域占据重要地位。

    1. 简单的通信协议，通信协议有tcp,udp,http协议，通信序列化协议有xml,json等来传数据，使通信的两方能互相识别。memcached使用tcp协议通信，其序列化协议是自定义的文本协议，非常简单。
    2. 丰富的客户端程序，memcached的通信协议非常简单，能支持该协议的客户端都可以和memcached服务器通信，几乎支持所有主流的网站编程语言，如java,c/c++,perl,php,python,ruby等。
    3. 高性能的网络通信，memcached服务端通信模块基于libevent,一个支持事件触发的网络通信程序库，libevent在稳定的长连接方面的表现正式memcached所需要的。
    4. 高效的内存管理，最小内存块是chunk，固定大小，然后一组chunk组成slab,一组slab组成slab_class, 采用LRU算法释放最近最久未被访问的内存； *这种方式会带来内存浪费问题，如果启动参数配置不合理，浪费会更加惊人！使用需注意。*
    5. 互不通信的服务器集群架构，正是这个特性使memcached从Jboss cache, oscache等众多分布式缓存产品脱颖而出，满足网站对海量缓存数据的需求，而其客户端路由算法一致性hash更成为数据存储伸缩性架构设计的经典模式（第6章）。
   实际也正是集群内服务器互不通信使得集群可以做到几乎无限制的线性伸缩，这也是目前流行的许多大数据技术的基本架构特点。

##### 4.3.2 异步操作
 > 使用消息队列将调用异步化，可改善网站的扩展性，事实上，使用消息队列还可以提升网站系统的性能。
 >> 消息队列服务器，未使用时：1.客户端发起请求-->网站应用服务器-->数据库服务器
                    使用时：  2.客户端发起请求-->网站应用服务器-->消息队列服务器-->数据库服务器

     在不使用消息队列时，客户端请求数据直接写入数据库，在高并发情况下会对数据库造成很大压力，同事响应延迟加剧。在使用消息队列后，用户请求的数据发送给消息队列后立即返回，再由消费队列的消费者进程（通常情况下，该进程通常独立部署在专门的服务器集群上）从队列中获取数据，异步写入数据库。由于消息队列服务器处理速度远快于数据库（消息队列服务器比数据库具有更好的伸缩性），因此用户的响应延迟也可得到有效改善。
     消息队列有很好的流量削峰作用。通过异步处理，将短时间高并发产生的事务消息存储在消息队列中，从而削平高峰期的并发事务。
     需要注意的是，由于数据写入消息队列后立即返回给用户，数据在后续的业务校验，写数据库操作可能失败，因此在使用消息队列进行业务异步处理后，需要适当修改业务流程进行配合，如订单提交后，
    订单数据写入消息队列，不能立即返回用户订单提交成功，需要在消息队列的订单消费者进程真正处理完该订单，甚至商品出库后，再通知电子邮件或sms消息通知用户订单成功，以免交易纠纷。

##### 4.3.3 使用集群
     在网站高并发访问的场景下，使用负载均衡技术为一个应用构建一个由多台服务器组成的服务器集群，将并发访问请求分发到多台服务器上，减轻单一服务器压力，提高响应速度。
     负载均衡过程； 用户浏览器-->负载均衡服务器-->web服务器集群

##### 4.3.4 代码优化
     网站的业务逻辑实现代码主要部署在应用服务器上，需要处理复杂的并发事务。下面主要关注几个优化方面：
      1. 多线程
       多用户访问时网站的基本需求，大型网站的并发用户数会达到数万，单太服务器的并发用户也会达到数百。CGI编程时代，每个用户请求都会创建一个独立的系统进程去处理。由于线程比进程更轻量，更少战友系统资源，切换代价更小，所以目前主要的web应用服务器都采用多线程的方式响应并发用户请求，因此网站开发天然就是多线程编程。
      从资源利用的角度看:  使用多线程主要是为了更好的利用多核cpu,当前线程进行io处理，会被阻塞释放cpu以等待io操作完成，io(不管是磁盘id还是网络id)通常需要较长时间。cpu可以调度其他线程进行处理。
        线程启动数：   启动线程数=[任务执行时间/(任务执行时间-IO等待时间)]*CPU内核数。
            最佳启动线程数和CPU内核数量成正比，和IO阻塞时间成反比。如果任务都是cpu计算型任务，那么线程数量最多不超过cpu内核数。因为启动再多线程，CPU也来不及调度；相反如果是任务需要等待磁盘操作， 网络响应，那么多启动线程有助于提高任务并发度，提高系统吞吐能力，改善系统性能。
        线程安全问题：  多线程使用另外一个问题是线程安全问题，即多线程并发对某个资源进行修改，导致数据混乱。这也是缺乏经验的网络工程师最容易犯错的地方。线程安全bug难以测试和重现，网站故障中许多“灵异事件”都和多线程并发问题有关。对网站而言，每一行代码都会被多线程执行，因为用户的请求是并发提交的，所有的资源----对象，内存，文件，数据库，乃至另一个线程都可能被多线程并发访问。
       
        编程中，解决线程安全的主要手段有以下几点。
        * 将对象设计成无状态对象，java中servlet就是无状态对象
        * 使用局部对象， 即在方法内部创建对象，这样对象会被每个进入方法的线程创建。除非线程有意识地将这些对象传递给其他线程，否则不会出现对象被多线程并发访问的清形。
        * 并发访问资源时使用锁， 即多线程访问资源时，对资源加锁，使多线程并发操作转化为顺序操作，避免资源被并发修改。
     2. 资源复用
        系统运行时，要尽量减少那些开销很大的系统资源的创建和销毁，如数据库连接、网络通信连接、线程、复杂对象等，资源复用主要有两种模式：单例singleton和对象池object pool。 
        目前web开发中主要使用贫血模式，从service到dao都是些无状态对象，无需重复创建，使用单例模式就自然而然了，事实上，java开发常用的对象容器spring默认构造的对象都是单例的，spring的单例是spring容器管理的单例，而不是单例模式构造的单例。
        对象池模式通过复用对象实例，减少对象创建和资源消耗。实际使用中，数据库连接基本使用连接池（connection pool）方式。数据库连接对象创建好以后，将连接对象放入对象连接池中，应用程序要连接时，就从对象池中获取一个空闲的连接使用，使用完毕再将该对象归还到对象池中即可，不需要创建新的连接。
        前面说过，对于每个webhttp请求，web应用服务器都需要创建一个独立的线程去处理，这方面，应用服务器也采用线程池的方式。 本质上连接池，线程池都是对象池。池管理方式基本相同。
     3. 数据机构
        求hashcode过程中，相似字符串hashcode可能比较相近，在某些应用场景是不符合规范的，此时可以对原本的字符串取信息指纹，再对指纹求hashCode,
     4. 垃圾回收
        如果web应用运行在jvm等具有垃圾回收功能发的环境中，那么垃圾回收可能对系统性能有巨大影响，理解垃圾回收机制有助于程序优化和参数调优，以及编写安全的代码。
        java JVM应该根据系统业务特点和对象生命周期，合理设置young generation和old generation大小，尽量减少full GC,事实上，某些web应用在整个运行期间可以做到从来不进行full GC。

#### 4.4  存储性能优化      
        在网站应用中，海量数据读写对磁盘访问造成很大压力，缓存虽然可以解决一部分问题，但是磁盘仍然是系统最严重的瓶颈。磁盘存储着网站最重要的数据，磁盘的可用性和容错性也至关重要。   

##### 4.4.1 机械硬盘 vs. 固态硬盘
        机械硬盘是目前最常用的一种硬盘，通过磁头臂带动磁头到指定的磁盘位置访问数据。由于每次访问数据需要磁头臂，因此机械硬盘在数据连续访问（要访问的数据存储在连续的磁盘空间上）和
随机访问（要访问的数据存储在不连续的磁盘空间）时，由于移动磁头臂的次数相差巨大，性能表现也非常大。
        固态硬盘称SSD硬盘或Flash硬盘，这种硬盘没有机械装置，数据存储在可持久记忆的硅晶体上，因此可以向内存一样快速随机访问。而且ssd具有更小的功耗和更少的磁盘震动与噪声。
        在网站应用中，大部分数据访问都是随机的，这种情况下ssd具有更好的性能表现。目前ssd硬盘还不太成熟，可靠性，性价有待提升，但随着SSD工艺水平的提高，逐步替代传统机械硬盘是迟早的事。

##### 4.4.2 B+树 vs. LSM 树
	 B+ 树： 关系型数据库
        上一节提到，由于传统的机械磁盘具有快速顺序读写、慢速随机杜尔西的访问特性，这个特性对磁盘存储结构和算法的选择影响甚大。
        为了改善数据访问特性，文件系统或数据库系统通常会对数据排序后存储，加快数据检索速度，这就需要保证数据在不断更新、插入、删除后依然有序，传统关系型数据库的做法是使用b+树。
        B+树是一种专门针对磁盘存储而优化的N叉排序树，以树节点为单位存储到磁盘中，从根节点开始查找所需数据所在的节点编号和磁盘位置，将其加载到内存中然后继续查找，指导找到所需的数据。
        目前数据库多采用2级索引的b+树，树的层次最多3层，因此可能需要5此磁盘访问才能更新一条记录。（3此磁盘访问获得数据索引及行ID，然后再进行一次数据文件读操作及一次数据文件写操作）。
        但是由于每次磁盘访问都是随机的，而传统机械硬盘在数据随机访问时性能较差，每次数据访问都需要多次访问磁盘影响数据访问性能。

        LSM树：NoSql产品
        目前许多NoSql产品采用LSM树作为主要数据结构。

        LSM树可以看做是一个N阶合并树，数据写操作都在内存进行，这些数据在内存中仍然是一棵排序树，当数据量超过预定的内存阀值时，会将这颗排序树和磁盘上最新的排序树合并。当这棵排序树的数据量也超过设定
阀值后，和磁盘上下一级的排序树合并。合并过程中会用新的数据覆盖就的数据（或记录为不同版本）。
        在需要进行读操作时，首先会从内存中的排序树读数据，如果内存没有才去磁盘中找。
        在LSM树上进行一次数据更新不需要磁盘访问，在内存即可完成，速度远快于B+树。当数据访问以写操作为主，读操作则集中在最近写入的数据上时，使用LSM数可极大程度地减少磁盘访问次数，加快访问速度。

##### 4.4.3 RAID VS. HDFS
        RAID 廉价磁盘冗余阵列技术主要是为了改善磁盘的访问延迟，增强磁盘的可用性和容错能力。目前服务器级别的计算机都支持插入多块磁盘（8+），通过使用RAID技术，实现数据在多块磁盘上并发读写和数据备份。
        RAID技术可以通过硬件实现，比如专用的RAID卡或者主板直接支持，也可以通过软件实现。RAID技术在传统关系型数据库以文件系统中应用比较广泛，但是在大型网站比较喜欢使用的是NoSql.以及分布式文件系统
中，RAID技术却遭到冷落。

        例如在HDFS（hadoop分布式文件系统）中，系统在整个存储集群的多台服务器上进行数据并发读写和备份，可以看作在服务器集群规模上实现了类似RAID的功能，因此不需要磁盘RAID。
        HDFS以块（BLOCK）为单位管理文件内容，一个文件被分割为若干个BLOCK，当应用程序写文件时，每写完一个BLOCK，HDFS会自动将此BLOCK备份到另外2台机器上。相当于实现了RAID复制备份功能。
        当对文件进行处理计算时，通过MapReduce并发计算任务框架，可以启动多个计算子任务（MapReduce Task）,同时（并发读）读取多个BLOCK，并发处理，相当于实现了RAID0的并发访问功能。
   _HDFS配合MapReduce等并行计算框架进行大数据处理时，可以在整个集群上并发读写访问所有的磁盘，无需RAID支持。_


####  4.5 小结
        网站性能优化技术是在网站性能遇到问题时的解决方案。而网站性能问题很多事在用户高并发访问时产生的，所以网站性能优化的主要工作是改善并发用户访问情况下的网站响应速度。
        网站性能对用户而言就是一种主观感受，性能优化目的是让用户感觉很快，离开这个目的追求技术，是舍本逐末，架构师需要明白。
        技术是为业务服务的，性能优化也需要全面考虑，综合权衡效果，做出选择方案。
 >前沿技术总是出现在前沿业务领域，新技术的出现又会驱动企业开展新的业务。亚马孙等互联网公司利用自己的技术优势进军企业级市场，以技术驱动业务，开展云计算，SaaS等新兴IT业务。逐步蚕食IBM,HP,
ORACLE等传统软件巨头的市场。

###  5. 万无一失：网站的高可用架构

#### 5.1 网站可用性的度量与考核
        网站的页面能呈现在最终用户面前，需要经历很多环节，要保证一个网站永远完全可用几乎是一件不可能完成的使命。

##### 5.1.1 网站可用性度量
       对于网站而言，达到2个9 99%是基本可用。 4个9，99.99%是具有自动恢复功能的高可用。达到4个9或5个9不近是靠实力，责任心也需要一定运气。目前qq服务可用性是4个9，而twitter网站可用性不足2个9.所以常用twitter用户可能会遇到过服务不可用的鲸鱼页面。

##### 5.1.2 网站的可用性考核
       可用性考核会分一个层级，A,B,C等级别区分故障，落实责任。另外不同公司在不同发展期侧重点不同，对可用性要求的程度也有差别。

#### 5.2 高可用的网站架构
       典型的分层模型即为应用层、服务层、数据层。各层之间相对独立，应用层负责业务逻辑处理，服务层负责提供可复用的服务；数据层负责数据的存储与访问。小型网站部署时，通常将应用和服务层部署在一起，数据层另外部署。大型网站架构中，划分的粒度会更小，更详细，结构更复杂。
       
       大网站中，不同的业务产品会部署到不同的服务器集群上，例如“某站”的文库、贴吧、百科等属于不同的产品，部署在格子独立的服务器集群上，互不相干。这些产品又依赖一些共同的复用业务，如注册登录服务，session管理服务、账户管理服务等，这些可复用的业务服务也各自部署在独立的服务器集群上。 至于数据层，数据库服务、文件服务、缓存服务、搜索服务等数据存储于访问服务都部署在各自独立的服务器集群上。

       “某站”应用层（文库，贴吧，知道，百科），服务层（账户服务，session服务，登录服务），数据层（数据库服务，文件服务，缓存服务，搜索服务）；
       位于应用层的服务器通常为了应对高并发的访问请求，会通过负载均衡设备将一组服务器组成一个集群共同对外提供服务，当负载均衡设备通过心跳监测等手段监控到某台应用服务器不可用时，将其从集群列表剔除，并将请求分发到集群中其他可用的服务器上，使整个集群保持可用，从而实现高并发。
       位于服务层的服务器情况与应用层类似，通过集群实现高可用，只是这些服务器被应用层通过“分布式服务调用框架”访问。分布式服务调用框架会在应用层客户端程序中实现软件负载均衡，并通过服务注册中心对提供服务的服务器进行心跳监测，发现服务不可用，或新增服务，都会修改服务访问列表。
       位于数据层的服务器情况比较特殊，数据服务器上存储着数据，为了保证服务器宕机时数据不丢失，数据访问服务不中断，需要在数据写入时进行数据同步复制，将数据写入多台服务器上，实现数据冗余备份，当数据服务器宕机时，应用服务将访问切换到有备份数据的服务器上。

       网站升级的频率很高，一周一次，甚至一天一次，所以架构需要考虑升级带来的服务器整体宕机问题。

#### 5.3 高可用的应用
       应用层主要处理网站应用的业务逻辑，因此有时也称作业务逻辑层，应用的一个显著特点是应用的无状态性。即每个应用实例（服务器）完全对等，不保存上下文信息，请求到任何服务器，处理结果是一样的。

##### 5.3.1 通过负载均衡进行无状态服务的失效转移
       不保存状态的应用给高可用的架构设计带来巨大便利，因为服务器是可随意替代的，对于应用服务器集群，实现服务器可用状态的实时监控、自动转移失败任务机制是负载均衡。
       负载均衡将流量和数据分摊到一个集群组成的服务器群，提高整体负载处理能力。开源免费的负载均衡软件和昂贵的负载均衡硬件都提供失效转移功能。

##### 5.3.2 应用服务器集群的session管理
       应用服务器的高可用架构设计主要基于服务无状态这一特性，实际上，业务总是有状态，要依赖状态。例如购物，社交网站，都需要记录近期状态。
       web应用中将这些多次请求修改使用的上下文对象称作会话（Session）,单机情况下，session可由部署在服务器上的Web容器（如Jboss）管理。在使用负载均衡的集群环境中，由于负载均衡服务器可能会将请求分发到集群任何一台应用服务器上，所以保证每次请求依然能获得正确的session比单机要复杂的多。
       
       集群环境下，session管理主要有以下几种手段。
      1. session复制，简单的方式，在大型网站中核心应用集群就是数千台服务器，同时在线用户可达到数千万，复制的劣势很明显，不适用这种方案。
      2. session绑定，session绑定可以利用负载均衡的源地址hash算法实现，负载均衡服务器总是将来源于同一IP的请求分发到同一台服务器上，又称为会话黏滞，即固定（唯一服务器），但是这不符合对系统高可用要求，所以实际也不适用。
      3. 利用cookie记录session，早期的企业应用系统使用C/S架构，一种管理session方式是将session记录放在客户端，每次请求服务器时，将session放在请求中发给服务端，服务端再将处理完请求后再将修改后的session响应给客户端。而网站没有客户端，但是可以利用浏览器支持cookie记录session； 利用cookie记录session也有一些缺点，比如受cookie大小限制，用户可以关闭cookie，但是cookie简单易用，可用性高，支应用服务器线性伸缩，而大部分应用需要cookie比较小，因此事实上，许多网站都或多或少地使用cookie记录session；
      4. session服务器
         综合以上问题，有没有一种可用性高，伸缩性好，性能还不错，对信息大小有没有限制的服务器集群session管理方案呢？
         答案就是session服务器。利用独立部署的session服务器（集群），同一管理session。应用服务器每次读写session时，都访问session服务器。

         对于有状态的session服务器，一种比较简单的方法时利用分布式缓存、数据库等，在这些产品的基础上进行包装，使其符合session的存储和访问要求。如果业务场景对session管理有比较高的要求，比如利用session服务集成单点登录（SSO），用户服务等功能，则需要开发专门的session服务管理平台。

#### 5.4 高可用的服务
        可复用的服务模块为业务产品提供基础公共服务，大型网站中这些服务通常都独立分布式部署，被具体应用远程调用。同样是无状态的服务，因此可以使用类似负载均衡的失效转移策略实现高可用服务。

       除此之外，具体实践中，还有以下几点高可用的服务策略：
        1. 分级管理
          运维上将服务器进行分级管理，核心应用和服务优先使用更好的硬件。同时服务器部署上也进行必要的隔离，避免故障的连锁反应。
        2. 超时设置
          由于服务器宕机，线程死多等原因，可能导致应用程序对服务端的调用失去响应，进而导致用户请求长时间得不到响应，还占用应用程序的资源。此时可以在应用程序设置超时的事件，一旦超时，通信框架抛出异常。应用程序重新选择调用方式。
        3. 异步调用
          应用对服务的调用通过消息队列等异步方式完成，避免一个服务失败导致整个应用请求失败的情况。
          当然不是所有服务调用都可以异步调用，对于获取用户信息这类调用，还有必须确认调用成功才能继续下一步操作的应用也不合适使用异步调用。
        4. 服务降级
          网站访问高峰期，服务可能由于大量并发调用而性能下降，严重导致服务宕机。为保证核心功能可用，采用降级的手法减轻服务压力。
          如：拒绝服务，拒绝优先级地的应用的调用，减少服务调用并发数，或者随机拒绝部分请求调用，节约资源，如twitter比较喜欢随机拒绝服务，经常有用户看到自己访问的页面报错，而身边的人能用，再刷新一下就好了。
              关闭功能，关不部分不重要的功能，减少系统开销，如淘宝双11促销中，系统繁忙时关闭“评价”，“确认收货”等非核心服务，保证核心交易服务顺利完成。
        5. 幂等性设计
          即在服务层保证服务重复调用和调用一次产生的结果相同，即服务具有幂等性。 
          有的服务天然具有幂等性，如性别设置为男，不管设置多少次也没关系，而转账交易等操作，问题就比较复杂，需要通过交易编号等信息进行服务调用有效性校验，只有有效的操作才能进行。

#### 5.5 高可用的数据
        对网站而言，数据时最宝贵的财富，硬件可用购买，软件可用再重写，数据是历史积累下来的重要内容，（用户数据，交易数据，商品数据），一旦出问题，打击是毁灭性的。
        不同于高可用的应用和服务，由于数据存储服务器上保存的数据不同，当某台服务器宕机的时候，数据访问请求不能任意切换到集群中其他机器上。
        
        保证数据存储高可用的主要手段是数据备份和失效转移机制。
        数据备份是保证数据有多个副本，不丢失。失效转移是一个副本失效了，可以快速切换数据的其他副本访问。
        通过逻辑或物理分区的方式将每个应用的缓存部署在多台服务器上，任何一台服务器宕机引起的缓存失效都只影响应用缓存数据的一小部分，不会对应用性能和数据库负载造成太大影响。

##### 5.5.1 CAP原理
        在讨论高可用的数据服务架构之前，为了保证数据的高可用，网站通常会牺牲另一个也很重要的指标：数据一致性。
        高可用的数据有如下几个层面的含义。
       * 数据持久性：保证数据可持久存储，各种情况下不会出现数据丢失的问题，不但在写入数据时需要写入持久性存储，还需要将数据备份多个副本保存。
       * 数据可访问性：在多个备份副本的情况下，如果一个数据存储设备损坏，需要将数据访问切换到另一个数据存储设备上，这个过程要很快速完成（客户没感知），否则客户等待时间数据就是不可访问的。
       * 数据一致性：数据写入副本过程中，网络，服务器等某方面出现故障，数据就可能不一致。要保证应用可用，必须保证分布式处理系统的高可用性，此时数据不一致通常出现在系统高并发写操作或集群状态不稳时，应用系统需要对分布式数据处理系统的数据不一致性有所了解并进行某种意义上的补偿和纠错。避免数据不正确。
         数据一致性分为： 数据强一致，数据用户一致，数据最终一致。网站通常会综合各种场景，使存储系统达到用户一致，保证最终用户访问数据的正确性。

##### 5.5.2 数据备份
         数据冷备份廉价，但不能保持实时更新数据，有延迟性。
         数据热备份：  异步热备份和同步热备份。
         * 异步热备份即主从同步（多分数据副本写入操作异步完成，应用程序收到数据服务系统的写入操作成功响应时，只写成功一份）；数据写入时，由主存储服务器的写操作代理模块将数据写入本机存储系统后立即返回写操作成功，再又异步线程将写操作数据同步到从存储服务器。
         * 同步热备具体实现时，为了提高性能，在应用程序客户端并发向多个存储服务器同时写入数据，然后等待所有存储服务器都返回操作成功的响应后，再通知应用程序写操作成功。
         传统的企业级关系型数据库系统几乎都提供了数据实时备份的机制，而一开始就是为了大型网站设计的各种NoSql数据库更是将数据备份机制作为产品最主要的功能点之一。
         * 关系数据库热备机制就是常说的Master-Salve同步机制。 关系数据库热备份机制就是通常所说的Master-Salve同步机制，Master-Salve机制不但解决了数据备份问题，还改善了数据库系统的性能，解决负载压力。

##### 5.5.3 失效转移
       若数据服务器集群中任何一台服务器宕机，那么应用程序针对这台服务器的所有读写操作都需要重新路由到其他服务器，保证数据访问不会失败，这个过程叫失效转移。
       失效转移由3部分组成：失效确认、访问转移、数据恢复。

#### 5.6 高可用网站的质量保证
       本节介绍网站为了保证线上系统的可用性而采取的一些与传统软件开发不同的质量保证手段。

##### 5.6.1 网站发布
       网站发布频繁，大型网站可能每周都要发布几次更新，而重新部署新的应用事实上与服务器宕机效果相当；
       发布网站通常使用发布脚本来完成发布。关闭负载均衡服务器上一台或小批服务器路由，关闭应用，同步代码，启动应用，打开负载均衡服务器上这些服务器路由；然后依次循环此步骤，直到最后所有发布完成。

##### 5.6.2 自动化测试
       目前大部分网站都采用web自动化测试技术，使用自动化脚本或工具完成测试。比较流行的web自动化测试工具是thoughtWords开发的selenium.selenium运行在浏览器中，模拟用户操作进行测试。因此selenium可以同时完成web功能测试和浏览器兼容测试。
       大型网站通常也会开发自己的自动化测试工具，可以一键完成系统部署，测试数据生成、测试执行、测试报告生成等全部测试过程。许多网站测试工程师的编码能力毫不逊于软件工程师。

##### 5.6.3 预发布验证
       即使经过严格测试，软件部署到线上服务器后依然可能经常出现各种问题。主要原因是测试环境和线上环境并不相同。特别是应用需要依赖其他服务如数据库，缓存，公共业务服务等。以及一些第三方服务，如电信短信网关，银行网银接口。也许是数据库表结构不一致，也许是接口变化导致通信失效，也许是配置错误导致连接失败，或者是服务线上环境还没有准备好。这些问题都可能导致应用故障。
       因此在网站发布是，通常预发布到机器上，开发和测试进行预发布验证，执行典型的业务流程才会正式发布。
       “预发布服务器”是一种特殊用途的服务器，他和线上正式服务器唯一不同就是没有配置在负载均衡服务器上，外部用户无法访问。预发布服务器可以同步代码到正式应用服务器集群上，预发布服务器与正式服务器使用相同的物理环境，可能在同一个机架上，使用相同的线上配置，依赖相同的外部服务，网络工程师通常在自己的开发用计算机上配置hosts文件绑定域名ip关系直接使用ip地址访问预发布服务器，进行测试。
##### 5.6.4 代码控制
        当前主要有svn和git，git学习成本较高，但git成为网站的标准版本控制工具的优势此svn强。git应该会逐渐替代svn。git对分布式开发，分支开发等有更好的支持，
        容易在个开发分支上及时反映主干的最新更新，避免svn在最后提交分支代码时发现和主干代码差别太大难以merge成功。

##### 5.6.5 自动化发布
        网站新包发布也是一个非常棘手的问题，通常在周四发布，有3天时间准备，最后一天修复bug； 互联网有一种火车发布模型，正常流程下，可以做到发布过程无人值守，无需SCM参与，
        每个项目相关人员基于流程执行相应的操作，即可完成应用自动发布。人的干预越少，自动化程度越高。引入故障可能性越小，大家准时下班的可能性越大。

##### 5.6.6 灰度发布
        灰度发布，即在服务器集群中，选择一部分服务发布，测试观察，隔一天或一定时间再发布一部分服务器，相同于测试服的效果。

####  5.7 网站运行监控
        网站运行必须有监控，运维没有监控的网站如同盲人骑瞎马，更不要谈提高可用性，减少故障率等。

##### 5.7.1 监控数据采集
        广义指供数据分析师和产品设计师使用的网站用户行为日志、业务运行数据，以及供运维工程师和开发工程师使用的系统性能数据等。
        1.用户行为与日志收集。目前许多网站逐步开发基于实时计算框架Storm的日志统计与分析工具。
        2.服务器性能收集。一个被网站广泛使用的性能监控工具是Ganglia,支持大规模服务器集群，并以图形方式展示实时性能曲线。如系统load，内存占用，磁盘io，网络io等。
        3.运行数据报告。除了服务器性能，网站还需要监控一些与具体业务场景相关的技术和业务指标，如缓冲命中率、平均响应延迟时间、每分钟发送邮件数据、待处理的任务总数等。
          运行数据需要在具体程序中采集并报告，汇总同一显示，应用程序需要在代码中处理运行数据采集的逻辑。

##### 5.7.2 监控管理
        监控数据采集后，除了用作系统性能评估、集群规模性伸缩与场外，还可以实时监控数据进行风险预警（系统报警）、对服务器进行失效转移（失效转移）、自动优雅降级、自动负载均衡，最大化利用集群资源。

##### 5.8 小结
        可用性关乎网站的生死存亡，可用性是第一要求，其他的性能，扩展性，伸缩性都在可用性之后。


### 6 永无止境：网站的伸缩性架构
#### 6.1 网站架构的伸缩性设计
        网站跟随业务都是从一个小型的网站逐渐发展扩大的。所以在不同时期架构选型策略不同不能生搬硬套。同时要注意的是网站不是一开始就建立一个大的系统，而是逐步扩展规模，不能一开始就企图打造一个大的网站。
        网站的伸缩性分为2种，一种是根据功能通过物理分离实现伸缩，一种是单一功能集群伸缩，而集群伸缩性又可分为应用服务器集群伸缩性和数据服务器集群伸缩性。这两者对于数据状态管理的不同，
        技术实现也有非常大的区别。而数据服务器集群也可分为缓存数据服务器和存储数据服务器集群。这两者集群的伸缩性设计也不相同。

#### 6.2 应用服务器集群的伸缩性设计。
        应用服务器应该是无状态的，即应用服务器不存储请求上下文信息，许多应用服务器组成一个集群，用户随机访问结果都一致，即可构成一个集群。
        负载均衡服务器即是一个http请求分发装置，可以向新上线的服务器分发任务，发现已经下线的服务器，这样就实现了应用服务器集群的伸缩性。

> 负载均衡是网站必不可少的技术手段，可以提升网站伸缩性，可以改善网站可用性，提升响应速度。实现手段有硬件，软件，商业产品，开源软件等。。
  负载均衡主要有以下几种实现方式：
  * http重定向负载均衡，根据域名解析到负载均衡服务器，然后负载均衡服务器返回转化后的真实地址，浏览器再重新请求。实际应用的少。
  * DNS域名解析负载均衡，域名服务商的DNS配置多个ip地址，根据负载均衡算法返回某个ip给浏览器；
事实上，大型的网站总是部分使用DNS域名解析，利用域名解析作为第一级负载均衡手段。再进入内网提供负载均衡服务的服务器。
  * 反向代理负载均衡，反向代理在应用服务器之前，位置与负载均衡服务器同一级，大多数兼具负载均衡功能。由于web服务器不直接对外提供访问，
因此web服务器不需要访问外部ip地址。而反向代理服务器需要配置双网卡和内部外部2套ip； 在实现负载均衡功能时，通过负载均衡算法计算出真实ip，
转发请求给应用服务器，应用服务器处理完之后返回给反向代理服务器，反向代理服务器再返回请求给用户。反向代理服务器工作在http层，也叫做应用层负载均衡。
  * IP负载均衡，在网络层修改目的地址进行负载均衡，然后返回数据包时，修改包源地址为自己。
  * 数据链路层负载均衡，指的是通信协议的数据链路层修改mac地址进行负载均衡。 使用三角传输模式的链路层负载均衡是目前大型网站使用最广泛的一种负载均衡手段。在Linux平台最好用的开源产品是LVS（Linux Virtual Server）。
  * 负载均衡算法，轮询，加权轮询，随机，最少连接，源地址散列。 源地址散列可以实现会话黏滞，服务器保留请求的上下文信息。

#### 6.3 分布式缓存集群的伸缩性设计。
      分布式缓存不同于应用服务器集群的伸缩性设计，不能简单的使用负载均衡手段来实现。分布式缓村服务器集群中不同服务器缓存的数据各不相同，缓存访问请求
      必须先找到缓存有需要数据的服务器，然后才可访问。  * 新加入缓存服务器后应使整个缓存服务器集群中已经缓存的数据尽可能还被访问到，这是分布式缓存集群伸缩性设计的主要目标。

##### 6.3.1 Memcached分布式缓存集群的访问模型
      以memcached为代表的分布式缓存访问模型如图所示，*应用程序* 通过memcached客户端访问memcached服务器集群，memcached客户端主要由一组API，memcached服务器集群路由算法，memcached服务器集群列表及通信模块构成。
      读写缓存的一般步骤是，根据应用程序请求的key,由路由算法计算缓存位于缓存服务器集群的位置（ip）,由通信模块发起通信，写缓存或读缓存。唯一的key对应唯一的缓存存储位置。

##### 6.3.2 Memcached分布式缓存集群的伸缩性挑战
      在memcached分布式缓存系统中，对于服务器集群的管理，路由算法至关重要，和负载均衡算法一样。决定着究竟访问集群中那台服务器。
      在网站业务中，大部分业务数据读操作请求事实上是通过缓存获取的，只有少量数据读数据库完成，因此数据库的负载能力是在有缓存的前提下设计的。
      新加入缓存服务器是为了降低数据库的负载压力，但是新加入缓存服务器是一个比较复杂的问题，操作不当会导致数据库的崩溃，一旦崩溃启动就很困难不是简单的启动数据库；
      一次解决办法是在网站访问量最少的时候扩容缓存服务器集群，这时候对数据库的负载冲力最小。然后通过模拟请求的方式逐渐预热缓存，使缓存服务器中的数据重新分布。

##### 6.3.3 分布式缓存的一致性hash算法
      通过改进路由算法，使得新加入的服务器不影响大部分缓存数据的正确命中呢？ 目前比较流行的算法是一致性hash算法。
      一致性hash算法通过一个叫做一致性hash环的数据结构实现key到缓存服务器的hash映射。

#### 6.4 数据存储服务器集群的伸缩性设计
     与缓存服务器集群的伸缩性设计不同，数据存储服务器集群的伸缩性对数据持久性和可用性提出了更高的要求。数据库存储服务器集群在任何情况下都要
     必须保证数据的可用性和正确性。具体来说，可用分为关系数据库集群的伸缩性设计和NoSql数据库的伸缩性设计。

##### 6.4.1 关系型数据库集群的伸缩性设计
     * 主从数据库设计。主库负责写，多个从库负责读，从库从主库同步数据。
     * 数据分库，除了读写分离，业务分割应用在数据库，不同业务的数据表部署在不同的数据库集群上，即俗称的数据分库，但这种方式跨库的表不能进行join操作。
     * 数据分片，在大型网站中，即使进行了分库和主从复制，对一些单表数据仍然很大的表，如淘宝的商品数据库，还需要分片。目前比较成熟的支持分片的数据库产品主要有开源的Amoeba和Cobar(http://code.alibabatech.com/wike/display/cobar/Home).这两个产品架构相似。

  图6.15 Cobar部署模型
      cobar是一个分布式关系数据库访问代理，介于应用服务器和数据库服务器之间（cobar也支持非独立部署，以lib的方式和应用程序部署在一起）。应用程序通过jdbc驱动访问cobar集群，cobar服务器根据sql和分库规则分解sql,分发到mysql集群不同的数据库实例上执行（每个mysql实例都部署主/从结构，保证数据高可用）。   
  图6.16 Cobar系统组件模型
      cobar服务器由前端通信模块，sql解析模块，sql路由模块，sql执行代理模块，结果合并模块。后端通信模块组成；
      前端通信模块负责和应用程序通信，接受到sql请求后转交给sql解析模块，sql解析根据sql中的路由规则查询条件再转交给sql路由模块，sql路由模块根据路由规则配置（如奇数id路由值数据库A，偶数id路由至数据库B）将应用程序提交的SQL分解成两条sql转交给sql执行代理模块，发送至数据库A，数据库B分别执行；
      数据库A和数据库B的执行结果返回值SQL执行模块，通过结果合并模块将2个返回结果集合合并成一个结果集，最终返回给应用程序，完成分布式数据库中的一次访问请求。
      * cobar集群的伸缩，cobar服务器集群的伸缩和mysql服务器集群的伸缩。
      应用程序通过cobar访问关系型数据库，cobar服务器处理消耗的时间是很少的，时间花费主要还是在myslq数据库端，性能基本和直接访问关系型数据库相当。
      cobar只能在单一数据库实例上处理查询请求，因此无法执行跨库的join操作，当然更不能执行跨库的事物处理。
  
      相比关系型数据库本身功能的优雅强大，目前各类分布式关系型数据库解决方案都显得非常简陋，限制了关系型数据库某些功能的使用，但是当业务面临不断增长的海量业务数据存储压力时，有不得不利用分布式关系型数据库的集群伸缩能力，这时就必须从业务上回避分布式关系型数据库的各种缺点：避免事务或利用事务补偿机制代替操作事务，分解数据库访问逻辑避免join操作等。

      除了上面提到的分布式数据库外，还有一种支持分布式数据库join操作执行复杂的SQL查询，如GreenPlum,这类数据库访问延迟比较大（可以想象，join操作需要在服务器间传输大量的数据），因此一般使用在数据仓库等非实时业务中。

##### 6.4.2 NoSql数据库的伸缩性设计
      NoSql，主要指非关系的、分布式的数据库设计模式。一般而言，NoSql数据库产品都放弃了关系数据库的2大重要基础：以关系代数为基础的结构化查询语句（SQL）和事物一致性（ACID）。而强化其他一些大型网站更关注的特性：高可用性和可伸缩性。
      开源社区有各种NoSql产品，其支持的数据结构和伸缩性也各不相同，目前而言，应用最广泛的是Apache Hbase.
      HBase为可伸缩海量数据存储而设计，实现面向在线业务的实时数据访问延迟。HBase的伸缩性主要依赖其可分裂的HRegion及可伸缩的分布式文件系统HDFS实现。

####  6.5 小结
     伸缩性架构设计能力是网站架构师的必备技能。伸缩性架构设计师简单的，稍有规模的网站都要求可伸缩，同时业界有许多成熟案例可借鉴，还有大量商业，开源的提供伸缩性能力的
     * 软硬件产品可供选择，而伸缩性设计又是复杂的，往往和可用性、正确性、性能等耦合在一起，改善网站伸缩性可能对其他性能产生影响，网站架构师必须对网站的商业目标，历史演化，技术路线了然于胸，甚至要兼考虑团队技术能力等等。
     * 一个具有良好伸缩性架构设计的网站，设计要走在业务发展前面，在业务需要处理更多访问和服务之前，就做好了充足准备；要做到先知先觉，万不能后知后觉。否则不仅解决问题莽撞，技术团队每天加班，疲于应对。架构师对网站伸缩性的把握，一线之间，天堂和地狱。

>> *高手定律 救世主定律*
>> 高手是在遇到问题不断解决顶着压力提升，遇到问题多了就成了高手，业务环境造就高手，例如在海量数据处理的场景可以成长出数据处理的高手。
>> 救世主定律，遇到问题，分析问题，解决问题。如果遇到问题匆匆从外面挖一个高手过来，指望高手可以如探囊取物轻松搞定，最后怕是只有彼此抱怨和伤害。许多问题只是看起来一样，具体问题具体对待，没有救世主。即没有救世主定律



###  7 随机应变： 网站的可拓展架构
      使用TOP（taobao open api）,一个技术熟练的淘宝客网站开发工程师只需要几个晚上的业务时间就可以开发部署一个炫目的购物导航网站。
      有的网站必须规定系统发布日，一到发布日就如临大敌，整个技术部加班通宵达旦，而有的网站就可以随时发布，新功能可以随时快速上线。
      这些都有赖于网站的扩展性架构设计，就是在对现有系统影响最小的情况下，系统功能可持续扩展即提升的能力。

#### 7.1 构建可扩展的网站架构




### 8. 固若金汤：网站的安全架构

#### 8.1 网站应用攻击与防御
      xss攻击和sql注入攻击构成网站应用攻击最主要的2中手段，全球大约有70%的web应用攻击都来自xss攻击和sql注入攻击。此外，常用的web应用还包括CSRF，Sessioin劫持手段。

##### 8.1.1 xss攻击
      xss攻击即跨站点脚本攻击。黑客通过篡改网页，注入恶意HTML脚本，在用户浏览网页时，控制用户浏览器进行恶意操作的一种攻击方式。
      常见xss攻击类型有2种，一种是反射性，攻击者诱使用户点击一个嵌入恶意脚本的链接，达到攻击的目的。攻击者采用xss攻击，偷取用户cookie，密码等重要数据，进而伪造交易，盗窃用户财产，窃取情报。
      另外一种xss是持久性攻击，黑客提交有恶意脚本的请求，保存在北攻击的web站点数据库中，用户浏览网页时，恶意脚本被包含在正常页面中，达到攻击的目的。这种攻击常使用在论坛，博客等web应用。

      xss攻击方式古老，却历久弥新，因此xss防公司也是非常复杂的。
      * 消毒，过滤转化HTML危险字符转义，消毒几乎是所有网站最必备的xss防攻击手段；
      * httponly, 通过对改cookie添加httponly属性，避免被攻击脚本窃取。

##### 8.1.2 注入攻击
      注入攻击主要有sql注入和os注入。sql注入在http请求中注入恶意的sql命令达到目的。
      sql注入，主要是要通过熟悉库表结构才可以注入sql恶意代码，防治sql注入首先要避免被攻击者猜测到表名等数据库表结构信息，此外还可以采取如下方式：
      消毒：对可能注入的sql过滤，如"drop table"; 参数绑定： 如一些ibatis,hibernate框架，实现sql预编译和参数绑定，攻击的恶意sql会被当做参数而不是sql命令执行。

##### 8.1.3 csrf攻击 
      csrf（跨站点请求伪造），攻击者通过跨站请求，以合法用户的身份进行非法操作；如转账交易，发表评论。核心是利用浏览器Cookie或服务器Session策略，盗取用户身份。
      响应的，csrf的防御手段主要是识别请求者的身份，主要有几种手法：
      * 表单token，csrf是一个伪造用户请求的操作，所以需要构造用户的所有参数才行。表单token通过在请求参数中增加随机数的办法来阻止攻击者获得请求参数：在表单页面中增加一个随机数作为token，每次响应页面的token都不同，从正常页面提交的访问会提交token，而伪造的请求无法获取该值，服务器检查token并校验正确性确定是否合法。
      * 验证码 ， 相对而言，验证码更加简单有效，以避免用户不知情的情况下呗攻击者伪造请求，但是这种方式用户体验比较差一点。所以在关键点使用，如支付交易页面。
      * referer check, http请求头的referer域中记录着请求来源，可通过检查请求来源，验证其是否合法，如果不是自己网站的网页，就拒绝。。（例如防止网站图片盗取，非本站的请求，不返回资源。）

##### 8.1.4 其他攻击和漏洞
      除了以上提到的常见攻击，还有一些漏洞容易被黑客利用。
      * Error Code; 错误回显，许多web服务器默认是打开异常信息输出的，服务器端未处理的异常堆栈信息会直线输出给客户端浏览器，黑客可以故意制造错误参数触发这些异常，通过异常信息判断网站代码，找出漏洞；处理方式也很简单，配置web服务参数，跳转到500专门的错误页面即可。web应用常用的MVC框架也有这个功能。
      * html注释；注释会在客户端显示，开发可能需要一些日志方便开发，但给黑客利用提供便利，程序在最终发布前应该进行代码review，避免HTML注释漏洞。
      * 文件上传：一般网站都有文件上传功能，但是如果上传了可执行的文件，则可以此为跳板，攻击服务器及其他机器，最有效的方式是设置文件白名单，只允许上文文件类型，地址可执行文件类型。
      * 路径便利： 
 
##### 8.1.5 web应用防火墙
      web应用防火墙可以集合以上功能于一身，这就方便了很多。
      ModSecurity是一个开源的web应用防火墙，探测攻击并保护web应用程序，既可嵌入到web服务器，也可以作为一个独立的应用程序启动。 ModSecurity最早只是apache的一个模块，现在已经有.net java等多个版本。
      ModSecurity是一个开源的web应用防火墙，探测攻击并保护web应用程序，既可以嵌入到web应用服务器中，也可以作为一个独立的应用程序启动。
      除了开源的ModeSecurity，还有一些商业产品也实现web应用防火墙功能，如NEC的SiteShell.

##### 8.1.6 网站安全漏洞扫描
      网站也需要安全漏洞扫描，网站安全漏洞扫描工具根据内置规则，构造具有攻击性的URL请求，模拟黑客攻击行为，用以发现网站安全漏洞的工具。
      许多大型网站的安全团队都有自己的开发漏洞扫描工具，不定期对网站服务器进行扫描，查漏补缺，市场上也有很多商用的网站安全漏洞扫描平台。

#### 8.2 信息加密技术及密钥安全管理
      通常，为了保护网站的敏感数据，应用需要对这些信息进行加密处理，（脱敏），信息加密技术科分为3类，单项散列加密，对称加密和非对称加密。
##### 8.2.1 单向散列加密
      单向散列不可逆，只能正向进行然后比对，常用作用户密码处理，通常会给散列算法加点盐（salt）,salt相当月加密的密钥，增加破解难度。
      常见的单向散列算法有md5,sha等。单向散列算法还有个特点是输入的任何微小变化都会导致输出完全不同，这个特性又是也会被用来生成信息摘要，计算具有高离散程度的随机数字用途。

##### 8.2.2 对称加密
      对称加密指加密和解密用的是同一个密钥，或可相互推算（加密算法，解密算法）；通常用在需要安全交换或存储的场合，如cookie加密，通信加密等。
      常用的对称加密算法有DES算法，RC算法等。对称加密是一种传统加密算法，也是最常用的加密手段，适用于绝大多数需要加密的场合。

##### 8.2.3 非对称加密
      非对称加密，加密和解密适用的密钥不是同一密钥，其中一个对外界公开叫做公钥，另一个只有所有者知道，被称作私钥，用公钥加密的信息必须要私钥解开，私钥加密的信息只有用公钥才能解开，理论上，不可以通过公钥计算得到私钥。
      非对称加密技术通常用在信息安全传输，数字签名等场合。
      *信息发送者A通过公开渠道获得信息接受者B的公钥，对提交信息进行加密，然后通过非安全传输通道将密文信息发送给B，B得到密文信息后，用自己的私钥对信息进行解密，获得原始的明文信息。
      即使密文信息在传输过程中遭到窃取，窃取着没有解密密钥也无法还原明文。
      *数字签名过程则相反，签名者用自己的私钥对信息进行加密，然后发送给对方，接收方用签名的公钥对信息进行解密，获得原始明文信息，由于私钥只有签名者拥有，因此该信息是不可抵赖的，具有签名的性质。

      在实际应用中，往往混合使用对称加密和非对称加密。先使用非对称加密技术对对称密钥进行安全传输，然后使用对称加密技术进行信息加解密和交换。而有时，对同一个数据的2此使用非对称加密，可同时实现信息
      安全传输和数字签名的目的。
      非对称加密的常用算法有RSA算法等。HTTPS传输中浏览器使用的数字证书实质上是经过权威机构认证的非对称加密的公钥。

##### 8.2.4 秘钥安全管理
      不管是哪种加密方式，密钥的安全保密效果是最重要的。而实际中，有的工程师直接把密钥写在源码中，稍微好一点的写道配置文件中，线上和开发环境配置不同的密钥。总之密钥本身是以明文的方式保存的，
      这样有很多人可以接触到，至少公司内部，密钥不是秘密。
      实践中，改善密钥安全性的手段有2中。
      * 一种是把密钥和算法放到一个独立的服务器上，甚至专门做成一个独立的硬件设施，对外提供加密和解密服务。应用系统通过调用这个服务，实现数据的加解密。由于密钥和算法独立维护，专人负责，
      使得密钥泄露的概率大大降低，但是这种方案成本较高，而且有可能会成为应用的瓶颈，每次加密，解密都需要进行一次远程服务调用，系统性能开销也很大。
      * 另一种方案是将加解密算法放到应用系统中，密钥则放在独立的服务器上，为了提高密钥的安全性，在存储时，密钥分片存储，不同的人管理每一片，兼顾安全性的同时又改善了性能。
      应用程序调用密钥安全管理系统提供的加解密服务接口对信息进行加解密，该接口实现了常用的加密解密算法并可根据需求任意扩展。加解密服务接口通过密钥服务器的密钥服务取得加解密密钥，
      并缓存在本地（定时更新）。而密钥服务器中的密钥则来自多个密钥存储服务器，专人专管，更有安全性。调用服务的密钥申请者，管理者，安全审核人员，可以方便的通过密钥管理控制台管理更新密钥。

#### 8.3 信息过滤与反垃圾
     过滤广告，垃圾信息，常用的手段有以下几种：

##### 8.3.1 文本匹配
      文本匹配主要解决敏感词过滤问题，通常网站有一份敏感词列表，对敏感词消毒处理（替换**）或拒绝发表。在大型网站过滤敏感词如果用正则表达式，效率奇差，这方面公开的算法有很多，
      基本上都是Trie树的变种，空间和时间复杂度都比较好的有双数组Trie算法等。
      另一种更简单的方法时通过构造多级Hash表进行文本匹配。
      有时候为了绕过敏感词检查，某些输入信息会做一些手脚，如“阿_拉_伯”,这时候还需要对信息做降噪预处理，然后再进行匹配。

##### 8.3.2 分类算法
      对广告贴，垃圾邮件等内容的识别比较好的自动化方法是采用分类算法。
      分类算法通过学习，先将批量的已分类的邮件样本（如50000封正常邮件，2000封垃圾邮件）输入分类算发进行训练，得到垃圾邮件分类模型，然后利用分类算法结合分类模型对待处理邮件进行识别。
      比较简单实用的分类算发有贝叶斯分类算法。贝叶斯算法认为特征值之间是独立的，所以也被称为朴素贝叶斯算法（Native Bayes）;这个假设很多时候是不成立的，特征值之间具有关联性，通过朴素
      贝叶斯算法增加特征值的关联依赖处理，得到TAN算法，更进一步，通过关联规则的聚类挖掘，得到更强大的算法，如ARCS算法等。但是由于贝叶斯分类算法简单，处理速度快，仍是许多实时在线系统反垃圾的首选。
      分类算法除了用于反垃圾，还可用于信息自动分类，门户网站可用该算法对采集来的新闻稿件进行自动分类，分发到不同频道上。

##### 8.3.3 黑名单
      将黑名单邮件地址记录下来，可以排除垃圾信息；黑名单也可以用于信息去重，如将文章标题或文章关键词段落记录到黑名单中，以减少搜索引擎收录重复信息等用途。
      黑名单可以通过hash表实现；在对过滤需求要求不完全精确的场景下，可用布隆过滤器代替Hash表。布隆过滤器只使用hash表所需内存的1/8；（某个测试场景中）
> hash表在数据量大的情况下，很消耗系统内存空间、

#### 8.4 电子商务风险控制
      电子商务网站的发展给人们带来便利的同时，网站风险和安全性也显得尤为重要。

##### 8.4.1 风险
      电子商务具有多种形式，B2B,B2C,C2C每种交易的场景都不相同。风险也各有特点，大致分为几种：
      * 账户风险： 包括账户被黑，恶意注册等情形。
      * 买家风险： 买家恶意下单，黄牛囤货，欺诈退款及常见于B2B交易的虚假询盘等。
      * 卖家风险，不良卖家进行恶意欺诈的行为。
      * 交易风险，信用卡盗刷，支付欺诈，洗钱套现等。

##### 8.4.2 风控
      大型网站都配备有专门的风控团队进行风险控制，风控手段也包括人工和机器控制。 机器自动识别高风险交易和信息发送给风控审核人员进行人工审核，机器自动风控的技术和方法也不断通过人工发现的新风险类型逐步完善。
      机器自动风控的技术手段主要有规则引擎和统计模型。
      1. 规则引擎； 当交易的某些指标满足一定条件时，被认为具有高风险的欺诈可能。大型网站运营过程中，会总结出数以千计的此类高风险交易规则，由于规则庞大，网站一般使用规则引擎技术处理此类问题。
      2. 统计模型， 规则引擎虽然简单，但随着规则条件增多，会出现冲突等情况，越来越难以维护，目前大型网站更倾向于使用统计模型进行风控。统计模型使用前面提到的分类算法或者更复杂的机器学习算法进行智能统计，通过训练大量的数据，准确率不低于规则引擎。

#### 8.5 小结
      世界上没有绝对的安全，就像没有绝对的自由一样，网站攻击与防御不断改进，日常可能随时出现新的安全漏洞，架构师需要每天打起100%精神，预防漏洞或攻击。

